{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "392237fb-c517-49ad-8e45-06832a15556f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data\n",
    "from torch_geometric.nn import GraphConv, global_add_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "\n",
    "#import networkx as nx\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.use_deterministic_algorithms(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5141c4f-4d94-47d0-aded-2adbe1905d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0+cu113'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b483336-265c-4494-85d6-c9ca62cbe72e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## graph convolutions\n",
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(self, output_dim, \n",
    "                 hidden_dim, \n",
    "                 node_features_dim,\n",
    "                 edge_features_dim=None):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.conv1 = GraphConv(node_features_dim, hidden_dim)\n",
    "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.conv4 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.conv5 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.conv6 = GraphConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.fc1 = Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, node_index, batch):\n",
    "        x = F.relu(self.conv1(x, node_index))\n",
    "        x = F.relu(self.conv2(x, node_index))\n",
    "        x = F.relu(self.conv3(x, node_index))\n",
    "        x = F.relu(self.conv4(x, node_index))\n",
    "        x = F.relu(self.conv5(x, node_index))\n",
    "        x = F.relu(self.conv6(x, node_index))\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ca39b-4ac7-4ffc-a175-5d0325d8ff5c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def node_features(graph_data):\n",
    "    properies = ['one_hot_atom', 'node_dm', 'totalNumHs', \n",
    "                 'totalatomDegree', 'hybridization', 'MO_contribution',\n",
    "                 'atomic_charges', 'bonded_valence']\n",
    "    properties_to_concat = []\n",
    "    for prop in properies:\n",
    "        if len(graph_data[prop].shape) == 1:\n",
    "            properties_to_concat.append(graph_data[prop].reshape(-1, 1))\n",
    "        else:\n",
    "            properties_to_concat.append(graph_data[prop])\n",
    "    graph_data.node_features = torch.cat(properties_to_concat, 1)\n",
    "    return graph_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0f224-5dba-4bba-b2d4-8c4066626a99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Feature scaling for the node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd1c3e-e8b3-4508-9b8c-f3345b320a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = MinMaxScaler().fit_transform(train_data[10].node_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9ddf1b-6558-4308-bb5a-6ccab9eecfa4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a2a5c-6ad6-4917-aa9c-386ee451d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71eb6ef-a0c7-46ee-89d7-3e514fb03e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee111e4c-3b9e-4f14-8d65-39654714405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ccaa5-6f22-44a0-a2f8-ff1e63a41b98",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GCNModel(output_dim=345*2, \n",
    "                 hidden_dim=2000, node_features_dim=1009).to(device) #, \n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "#scheduler \n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                          mode='min', \n",
    "                                                          patience=5,\n",
    "                                                          threshold=1e-6\n",
    "                                                         )\n",
    "lr_scheduler2 =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.1)\n",
    "\n",
    "loss = torch.nn.MSELoss()                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248da07-1ca8-42b5-baef-79cb7f69c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_GCN(train_loader, val_loader, model, optimizer, loss_func, N_epochs):\n",
    "    for epoch in tqdm(range(N_epochs)):\n",
    "        for batch_train in tqdm(train_loader, leave=True, total=len(train_loader)):\n",
    "            batch_train.to(device)\n",
    "            #batch_val.to(device)\n",
    "            \n",
    "            out_train = model(batch_train.node_features, batch_train.edge_index, batch_train.batch, node_features_dim=batch_train.node_features.shape[1])\n",
    "            #print(type(out_train), out_train.shape)\n",
    "            loss_train = loss_func(out_train.flatten(), torch.tensor(batch_train.y).flatten())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "        lr_scheduler2.step()\n",
    "        print(optimizer.param_groups[0]['lr'])\n",
    "            #break\n",
    "                \n",
    "        print(f'Epoch: {epoch}, Loss train : {loss_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad4ce1-dc36-4e91-bb65-db393533e392",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_GCN(train_loader, val_loader, model, optimizer, loss, N_epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed3b10a-bbaa-4df9-88f3-82a98e40a0a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "                out_val = model(batch_val.node_dm, batch_val.edge_index, batch_val.batch)\n",
    "                loss_val = loss_func(out_val.flatten(), torch.tensor(batch_val.y).flatten())\n",
    "            \n",
    ", Loss valid : {loss_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d914104-c81f-47c4-b100-4f6ee94aa27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f12a64-93dc-48b9-bac1-4a23f0d9ae41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856c055-80e2-4913-b638-5d8a8f1b8edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ab82cc-bf18-444a-b860-63f067c0ac5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Graph attention network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d59c78-ad32-4716-b12a-e992a3ca4029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GATlayer(nn.Module):\n",
    "    \"\"\"graph attention layer implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
    "        self.dropout = dropout\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n",
    "        nn.init.xavier_uniform_(self.W.data, gain=1.144)\n",
    "        self.a = nn.Parameter(torch.zeros(size=(2*out_features, 1)))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.144)\n",
    "        \n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "        \n",
    "    def forwrd(self, inp, adj):\n",
    "        h = torch.mm(inp, self.W)\n",
    "        N = h.size()[0]\n",
    "        \n",
    "        a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2 * self.out_features)\n",
    "        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))\n",
    "        \n",
    "        zero_vec = -9e15*(torch.ones_like(e))\n",
    "        attention = torch.where(adj>0, e, zero_vec)\n",
    "        \n",
    "        attention = F.softmax(attention, dim=1)\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "        h_prime = torch.matmul(attention, h)\n",
    "        \n",
    "        if self.concat:\n",
    "            return F.elu(h_prime)\n",
    "        else:\n",
    "            return h_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0739183-859a-41e2-b2de-ccc131aa7fb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## pytorch implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fddd97-c685-4586-b77c-fc9af8bd5968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db99bb-9aef-42cb-90bf-c8ecf92f0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_data = 'Cora'\n",
    "dataset = Planetoid(root= './' + name_data, name = name_data)\n",
    "dataset.transform = T.NormalizeFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63432f8-d860-4811-bfee-ca953d1b1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT,self).__init__()\n",
    "        self.hid = 8\n",
    "        self.in_head = 8\n",
    "        self.out_head = 1\n",
    "        \n",
    "        self.conv1 = GATConv(dataset.num_features, self.hid, heads=self.in_head, dropout=0.6)\n",
    "        self.conv2 = GATConv(self.hid*self.in_head, dataset.num_classes, heads=self.out_head, dropout=0.6)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index \n",
    "        \n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7536b0-6149-4961-9055-47dfcd83446e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = GAT().to(device)\n",
    "\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(2000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(loss)\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272fd6f-8af6-4c8b-bb70-3ebc442adbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0170d-f14f-4cec-9cfb-8f64e8b98816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e819eef-3aef-49b2-8e82-1710487b37f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f278be-9600-41c8-bf77-2c16fc47d8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a4d5e2-d159-4b34-88c6-4b405902a3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f944950-a039-47f6-a050-49c22d764eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc173c-72a3-459e-b302-be0b11ed56b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84791c-f5df-405f-a94f-91651fd0eb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccbcace6-0ea4-464b-96d4-40b3c31865cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 8 GAT layers + linear layers as transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a5acf-b9ee-4cc2-94b3-f916dc497990",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert pairwise distance to higher order features using RBF\n",
    "def rbf_smearing(distances, sigma):\n",
    "    \"\"\"function to return smeared distance\n",
    "    \"\"\"\n",
    "    return torch.exp(- distances / (2* sigma**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f8a060-19f6-4e27-80e9-b91276f30666",
   "metadata": {},
   "source": [
    "loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5775dd99-c6ab-43df-a7d0-ce9a3850ed2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomMDGATData(Dataset):\n",
    "    r\"\"\"creating the pytorch dataset from the saved sql database\n",
    "    \n",
    "    Args:\n",
    "        db_dir : dir to database with different tables representing the propeties\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, db_dir):\n",
    "        try:\n",
    "            conn = sqlite3.connect(db_dir)\n",
    "        except Error:\n",
    "            print(Error)\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'; \")\n",
    "        self._table_names = cursor.fetchall()\n",
    "        \n",
    "        self._dataframes = {}\n",
    "        \n",
    "        for table in self._table_names:\n",
    "            self._dataframes[table[0]] = pd.read_sql(f\"SELECT * FROM {table[0]}\", conn)\n",
    "        \n",
    "    def _choose_df(self, df_name):\n",
    "        df = self._dataframes[df_name].drop(['index'], axis=1)\n",
    "        df.columns = df.columns.astype(int)\n",
    "        return df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._choose_df('trajectory'))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        trajectory = torch.tensor(self._choose_df('trajectory')\\\n",
    "                                  .loc[idx].to_numpy().reshape(-1, 3), dtype=torch.float32)\n",
    "        force = torch.tensor(self._choose_df('force')\\\n",
    "                             .loc[idx].to_numpy().reshape(-1, 3), dtype=torch.float32)\n",
    "        energy = torch.tensor(self._choose_df('energies')\\\n",
    "                              .loc[idx].to_numpy(), dtype=torch.float32)\n",
    "        elements = self._choose_df('elements').loc[idx].to_list()\n",
    "        \n",
    "        z = self._choose_df('z').loc[idx].to_list()\n",
    "        \n",
    "        return {'trajectory' : trajectory, 'force' : force, \n",
    "                'energy' : energy, 'elements' : elements, 'z' : z}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10428369-0716-4525-b521-e1c0ee94a13f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peptide_dataset = torch.load('./GGGGR.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f9cc58-48c1-4527-ba80-d071fb944144",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trajectory': tensor([[20.6365,  7.4573, 10.2589],\n",
       "         [20.8772,  8.0381,  8.9844],\n",
       "         [19.5590,  8.2561,  8.2748],\n",
       "         [19.4328,  9.1515,  7.4074],\n",
       "         [21.4657,  8.9951,  8.9941],\n",
       "         [21.4325,  7.3725,  8.3204],\n",
       "         [20.4970,  8.2285, 10.8920],\n",
       "         [21.3709,  6.8386, 10.5706],\n",
       "         [18.6094,  7.4091,  8.6391],\n",
       "         [17.2701,  7.4081,  8.0193],\n",
       "         [17.1773,  7.0648,  6.5617],\n",
       "         [16.1413,  7.1310,  5.9130],\n",
       "         [16.6815,  6.6571,  8.5105],\n",
       "         [16.7327,  8.2857,  8.2390],\n",
       "         [18.8936,  6.8862,  9.4666],\n",
       "         [18.2978,  6.6908,  5.9187],\n",
       "         [18.3800,  6.5380,  4.5134],\n",
       "         [18.1985,  7.8844,  3.7685],\n",
       "         [17.6035,  7.9065,  2.7031],\n",
       "         [19.4454,  6.1644,  4.3119],\n",
       "         [17.6246,  5.7783,  4.1568],\n",
       "         [19.1399,  6.6516,  6.4866],\n",
       "         [18.8090,  8.9710,  4.3226],\n",
       "         [18.7881, 10.3292,  3.6948],\n",
       "         [17.4576, 11.0241,  3.7655],\n",
       "         [17.3465, 12.0666,  4.4646],\n",
       "         [19.4986, 10.9865,  4.2649],\n",
       "         [19.0815, 10.2764,  2.6332],\n",
       "         [19.0300,  8.9100,  5.3501],\n",
       "         [16.4361, 10.5750,  3.0341],\n",
       "         [15.3168, 11.5353,  2.6018],\n",
       "         [14.3294, 11.7940,  3.7560],\n",
       "         [13.1556, 11.3718,  3.6700],\n",
       "         [14.7722, 11.1935,  1.2520],\n",
       "         [15.3758, 11.7435,  0.5053],\n",
       "         [13.8627, 11.7255,  1.1316],\n",
       "         [14.6995,  9.7456,  0.7302],\n",
       "         [15.7066,  9.3138,  0.8461],\n",
       "         [14.4836,  9.7232, -0.3221],\n",
       "         [13.5569,  8.8741,  1.2948],\n",
       "         [13.6272,  7.8752,  0.9367],\n",
       "         [12.6242,  9.2828,  0.8482],\n",
       "         [13.3481,  9.0119,  2.7312],\n",
       "         [12.8235,  9.8140,  3.0820],\n",
       "         [14.0254,  8.3867,  3.6567],\n",
       "         [13.7354,  8.5441,  4.9510],\n",
       "         [13.1776,  9.3424,  5.2517],\n",
       "         [14.5146,  8.2042,  5.5523],\n",
       "         [14.9077,  7.4706,  3.2934],\n",
       "         [15.4440,  7.0082,  4.0290],\n",
       "         [15.2295,  7.5174,  2.3723],\n",
       "         [16.5619,  9.7376,  2.5017],\n",
       "         [15.8533, 12.4848,  2.4907],\n",
       "         [14.7823, 12.4898,  4.7289],\n",
       "         [15.7434, 12.6210,  4.6876]]),\n",
       " 'force': tensor([[-1.2173e-03, -1.2221e-02,  1.6104e-02],\n",
       "         [ 1.9214e-02,  3.3983e-02, -3.4291e-02],\n",
       "         [ 1.9299e-02,  9.6047e-02, -5.7048e-02],\n",
       "         [-3.1667e-04, -5.7411e-02,  2.7405e-02],\n",
       "         [-2.3996e-02, -2.3292e-02, -2.7454e-03],\n",
       "         [ 6.1091e-03, -7.9363e-03,  3.3098e-03],\n",
       "         [ 2.8475e-03, -1.0883e-02,  2.5026e-02],\n",
       "         [ 2.0847e-03,  7.4629e-03,  7.6665e-03],\n",
       "         [-4.7460e-02, -1.0966e-02, -3.2945e-02],\n",
       "         [ 4.8321e-02, -4.8360e-02,  3.0886e-02],\n",
       "         [ 3.3399e-02,  2.7015e-03, -4.9839e-02],\n",
       "         [-3.5459e-02,  1.3877e-02,  1.3091e-02],\n",
       "         [-8.4044e-03, -2.5340e-02,  1.6221e-02],\n",
       "         [-1.7529e-02,  5.7280e-02, -4.4203e-03],\n",
       "         [-1.5307e-02, -1.1450e-02,  3.1016e-03],\n",
       "         [ 2.5911e-02,  2.4731e-03,  7.5472e-02],\n",
       "         [ 3.0163e-02, -2.3031e-02, -2.9067e-02],\n",
       "         [ 1.5416e-02,  7.4535e-03, -9.6618e-05],\n",
       "         [ 2.8715e-03,  7.5333e-03, -1.0650e-02],\n",
       "         [-5.8576e-02,  1.4105e-02, -2.4582e-03],\n",
       "         [ 3.1913e-02,  3.3805e-02,  3.1855e-03],\n",
       "         [-9.3875e-03, -2.5898e-03, -1.3559e-02],\n",
       "         [-9.9919e-03,  1.9269e-03,  2.6649e-02],\n",
       "         [ 2.3141e-02, -2.9873e-02,  3.3260e-02],\n",
       "         [-1.6944e-02,  7.9203e-02,  5.4254e-02],\n",
       "         [ 6.3457e-03, -4.9790e-02, -4.2850e-02],\n",
       "         [-2.2320e-02, -2.9011e-02, -2.2284e-02],\n",
       "         [ 3.7191e-03, -8.9650e-03,  1.4673e-02],\n",
       "         [-3.2607e-03,  1.3705e-02, -4.6018e-02],\n",
       "         [-5.4379e-02,  4.5481e-02, -1.8850e-02],\n",
       "         [ 7.8488e-02, -2.0529e-02,  4.7697e-02],\n",
       "         [-8.2466e-02, -6.4155e-02, -6.9484e-02],\n",
       "         [ 7.8001e-02,  6.1772e-02,  3.8639e-02],\n",
       "         [ 2.1232e-02, -7.0504e-03, -6.2230e-02],\n",
       "         [ 8.6467e-03, -1.4576e-02,  1.3510e-02],\n",
       "         [-5.2167e-02,  6.0238e-03,  4.6293e-03],\n",
       "         [-2.6553e-03, -3.4341e-03,  4.3117e-02],\n",
       "         [-1.2425e-02, -1.0781e-02, -2.2655e-03],\n",
       "         [ 9.6203e-03,  1.5021e-02, -2.6012e-02],\n",
       "         [-2.4251e-02,  8.7933e-02,  1.0431e-02],\n",
       "         [ 3.8859e-03, -4.1489e-02,  4.8368e-03],\n",
       "         [ 1.7434e-02, -1.1988e-02,  8.3720e-03],\n",
       "         [-1.6841e-02, -1.0543e-02, -2.2767e-02],\n",
       "         [ 4.4046e-03,  4.3521e-03, -2.0783e-02],\n",
       "         [-1.7329e-02, -2.8341e-02, -8.3488e-04],\n",
       "         [ 4.3807e-02, -1.3214e-03,  2.6880e-02],\n",
       "         [ 1.1517e-02, -1.4338e-02, -6.0358e-03],\n",
       "         [-3.8101e-02,  1.6193e-02, -2.6976e-03],\n",
       "         [-1.0016e-02, -1.3910e-02,  6.5387e-02],\n",
       "         [ 9.3234e-04,  7.7779e-03, -1.8191e-02],\n",
       "         [ 3.1867e-02, -1.2054e-02, -4.2732e-02],\n",
       "         [ 8.0367e-03, -1.7858e-02, -8.1286e-03],\n",
       "         [-3.7465e-03,  2.5528e-03,  1.4194e-03],\n",
       "         [-4.9746e-02,  1.0962e-02,  4.2034e-02],\n",
       "         [ 4.5665e-02, -6.1391e-03, -7.9721e-03]]),\n",
       " 'energy': tensor([-1437.9592]),\n",
       " 'elements': ['N',\n",
       "  'C',\n",
       "  'C',\n",
       "  'O',\n",
       "  'H',\n",
       "  'H',\n",
       "  'H',\n",
       "  'H',\n",
       "  'N',\n",
       "  'C',\n",
       "  'C',\n",
       "  'O',\n",
       "  'H',\n",
       "  'H',\n",
       "  'H',\n",
       "  'N',\n",
       "  'C',\n",
       "  'C',\n",
       "  'O',\n",
       "  'H',\n",
       "  'H',\n",
       "  'H',\n",
       "  'N',\n",
       "  'C',\n",
       "  'C',\n",
       "  'O',\n",
       "  'H',\n",
       "  'H',\n",
       "  'H',\n",
       "  'N',\n",
       "  'C',\n",
       "  'C',\n",
       "  'O',\n",
       "  'C',\n",
       "  'H',\n",
       "  'H',\n",
       "  'C',\n",
       "  'H',\n",
       "  'H',\n",
       "  'C',\n",
       "  'H',\n",
       "  'H',\n",
       "  'N',\n",
       "  'H',\n",
       "  'C',\n",
       "  'N',\n",
       "  'H',\n",
       "  'H',\n",
       "  'N',\n",
       "  'H',\n",
       "  'H',\n",
       "  'H',\n",
       "  'H',\n",
       "  'O',\n",
       "  'H'],\n",
       " 'z': [7,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  6,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  8,\n",
       "  1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78497dab-3990-493b-b052-96a2bb12011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_layers = {\n",
    "    'GCN' : geom_nn.GCNConv,\n",
    "    'GAT' : geom_nn.GATConv,\n",
    "    'Graphconv' : geom_nn.GraphConv,\n",
    "    'GATv2' : geom_nn.GATv2Conv\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b833ae6a-1256-4e7e-a819-6157ff5adac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GraphData(nn.Module):\n",
    "    \"\"\"\n",
    "    class to get graph data from atromic coordinates and atom types\n",
    "    \"\"\"\n",
    "    def __init__(self, n_neighbors, radius):\n",
    "        super().__init__()\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.radius = radius\n",
    "        #self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "    def _atomType_embedding(self, elements):\n",
    "        if isinstance(elements, list)\\\n",
    "        and len(elements) != 0:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"the elements should be a non empty list\")\n",
    "        i = len(elements)\n",
    "        one_hot_m = np.eye(i, i)\n",
    "        np.random.shuffle(one_hot_m)\n",
    "        return {k:v for k, v in zip(elements, one_hot_m)}\n",
    "    \n",
    "    def pairwise_dists(self, atomic_coords):\n",
    "        nbrs = NearestNeighbors(\n",
    "            n_neighbors=self.n_neighbors, \n",
    "            radius=self.radius,\n",
    "            algorithm='ball_tree'\n",
    "        ).fit(atomic_coords)\n",
    "        distances, inds = nbrs.kneighbors(atomic_coords)\n",
    "        return distances, inds\n",
    "    \n",
    "    def _make_graph(self, atomic_coords, elements, atomic_numbers):\n",
    "        G = nx.DiGraph()\n",
    "        dists, inds = self.pairwise_dists(atomic_coords)\n",
    "        \n",
    "        all_edges = []\n",
    "        for i, (atom_dists, atom_neighbors) in enumerate(zip(dists, inds)):\n",
    "            for atom_dist, atom_neighbor \\\n",
    "            in zip(atom_dists[1:], atom_neighbors[1:]):\n",
    "                all_edges.append((i, atom_neighbor, {'r_ij' : atom_dist}))\n",
    "                \n",
    "        G.add_edges_from(all_edges)\n",
    "        \n",
    "        all_nodes = []\n",
    "        all_one_hot = self._atomType_embedding(list(set(elements)))\n",
    "        G.add_nodes_from([(node, {'atom_type' : all_one_hot[atom], 'z' : z})\n",
    "                         for node, (atom, z) in enumerate(zip(elements, atomic_numbers))\n",
    "                         ])\n",
    "        return G\n",
    "    def forward(self, atomic_coords, elements, atomic_numbers):\n",
    "        G = self._make_graph(atomic_coords, elements, atomic_numbers)\n",
    "        return from_networkx(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e649e55-b79f-4e98-acf9-087731c21bdc",
   "metadata": {},
   "source": [
    "test the GraphData class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b3a6cb-f0b7-470b-a9f7-42469d189e57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_graph = GraphData(n_neighbors=30, radius=10)\n",
    "\n",
    "atomic_coords, _, energy, _, elements = ggggh_dataset[1000]\n",
    "\n",
    "test_g = test_graph(atomic_coords, elements)\n",
    "\n",
    "#nx.draw(test_g, with_labels=True)\n",
    "test_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f636ef7-c693-4645-863c-42cf74d8bf48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651c84cd-7a2c-40e3-8024-1fa74786c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFExpansion(nn.Module):\n",
    "    \"\"\"class to expand the distances between nodes (atoms) by RBF\"\"\"\n",
    "    def __init__(self, r_max=1, r_min=0, gap=0.1):\n",
    "        super(RBFExpansion, self).__init__()\n",
    "        num_centers = int(np.ceil((r_max - r_min) / gap))\n",
    "        self.centers = np.linspace(r_max, r_min, num_centers)\n",
    "        self.centers = nn.Parameter(torch.tensor(self.centers).float(), requires_grad=False)\n",
    "        self.gamma = 1 / gap\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        device = self.centers.device\n",
    "        self.centers = nn.Parameter(self.centers.clone().detach().float(), requires_grad=False)\n",
    "        \n",
    "    def _minmax_rij(self, r_ij):\n",
    "        return MinMaxScaler().fit_transform(r_ij)\n",
    "    \n",
    "    def _standardScaler(self, r_ij):\n",
    "        return StandardScaler().fit_transform(r_ij)\n",
    "        \n",
    "    def forward(self, r_ij, minmax=False, standardScaler=False):\n",
    "        if minmax:\n",
    "            r_ij = torch.tensor(self._minmax_rij(r_ij.reshape(-1, 1)))\n",
    "        elif standardScaler:\n",
    "            r_ij = torch.tensor(self._standardScaler(r_ij).reshape(-1, 1))\n",
    "        else:\n",
    "            r_ij = r_ij.reshape(-1, 1)\n",
    "        radial = r_ij - self.centers\n",
    "        coef = - self.gamma\n",
    "        return torch.exp(coef * (radial ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d25b6c-e5e1-451b-b97d-5e7a83dbf499",
   "metadata": {},
   "source": [
    "test RBFExpansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77ab11-4189-4e77-ab8e-5919dbc7e631",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "r_ij = test_g.r_ij\n",
    "\n",
    "rbf_test = RBFExpansion(r_max=1, gap=0.2)\n",
    "rbf_r_ij = rbf_test(r_ij, minmax=True)\n",
    "\n",
    "rbf_r_ij.view(49, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0126cbc-7633-4e3e-b9ee-ecc229f0b8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a1d8968-d95d-4e3b-9f5a-4ca827bd0656",
   "metadata": {},
   "source": [
    "test the class of RBFExpansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb0907-ff2d-4fe2-80c7-47844fddbd09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rbfexp = RBFExpansion(r_max=1, gap=0.05)\n",
    "\n",
    "length_scaler = StandardScaler()\n",
    "\n",
    "scaled_rij = length_scaler.fit_transform(r_ij.reshape(-1, 1))\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "minmax_rij = minmax.fit_transform(scaled_rij)\n",
    "\n",
    "rbf_rij = rbfexp(torch.tensor(minmax_rij).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599d447-ff50-4361-88e1-b95c8bf145f9",
   "metadata": {},
   "source": [
    "## making the residual block for Linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b43f0353-3a0f-45d4-ac81-ebaa241ecb36",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBlockLinear(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(ResidualBlockLinear, self).__init__()\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.BatchNorm1d(c_in),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(c_in, c_out),\n",
    "            nn.BatchNorm1d(c_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(c_out, c_out)\n",
    "        )\n",
    "        self.downsample = nn.Conv1d(c_in, c_out, kernel_size=1, stride=1)\n",
    "        \n",
    "    def _init_parameters(self):\n",
    "        for layer in self.residual:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.residual(x)\n",
    "        out += residual\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5525e95a-68d1-424e-94ab-09ccff95d058",
   "metadata": {},
   "source": [
    "## making the residual block for GNN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1457d7-a8a8-4790-8332-d404f578e212",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBlockGAT(nn.Module):\n",
    "    def __init__(self, c_in, c_out, heads, layer_name='GATv2', dropout=0.1, **kwargs):\n",
    "        super(ResidualBlockGAT, self).__init__()\n",
    "        if layer_name == 'GATv2':\n",
    "            gnn_layer = gnn_layers[layer_name]\n",
    "            self.residual = [\n",
    "                nn.BatchNorm1d(c_in),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(),\n",
    "                gnn_layer(\n",
    "                    c_in,\n",
    "                    c_out,\n",
    "                    heads=heads,\n",
    "                    dropout=dropout\n",
    "                ),\n",
    "                nn.BatchNorm1d(c_out*heads),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(),\n",
    "                gnn_layer(\n",
    "                    c_out*heads,\n",
    "                    c_out,\n",
    "                    heads=heads,\n",
    "                    dropout=dropout\n",
    "                ),\n",
    "            ]\n",
    "            self.layers = nn.ModuleList(self.residual)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        residual = x\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, geom_nn.MessagePassing): \n",
    "                out = layer(x, edge_index) \n",
    "            else:\n",
    "                out = layer(x)\n",
    "        out += residual\n",
    "        return out                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5c53e-b8c3-49ca-886c-696f8958984d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64d869eb-39aa-44f7-928a-8c9c23ce1569",
   "metadata": {},
   "source": [
    "# ResNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a45875-4cd1-42db-8124-fd13a7ef1e80",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks : list, c_in, c_hidd, c_out):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_hidd = c_hidd\n",
    "        \n",
    "        res_blocks = []\n",
    "        self.in_layer = nn.Linear(c_in, c_hidd)\n",
    "        for size_block in num_blocks:\n",
    "            res_blocks.append(self._make_block(block, size_block))\n",
    "            \n",
    "        self.blocks = nn.ModuleList(res_blocks)\n",
    "        self.out_layer = nn.Linear(c_hidd, c_out)\n",
    "        \n",
    "    def _make_block(self, block, num_layers):\n",
    "        layers = []\n",
    "        self.c_in = self.c_hidd\n",
    "        for num_layer in range(num_layers):\n",
    "            layers.append(block(self.c_in, self.c_hidd))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.in_layer(x)\n",
    "        for layer in self.blocks:\n",
    "            out = layer(out)\n",
    "        out = self.out_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d77a456-267c-4954-ac2c-ceb102d73640",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GATResNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 block, \n",
    "                 num_blocks : list, \n",
    "                 c_in, c_hidd, \n",
    "                 c_out, heads, \n",
    "                 **kwargs):\n",
    "        super(GATResNet, self).__init__()\n",
    "        self.c_in=c_in\n",
    "        self.c_hidd=c_hidd\n",
    "        self.heads=heads\n",
    "        \n",
    "        #first layer of the GATResNet\n",
    "        gnn_layer = gnn_layers['GATv2']\n",
    "        self.layer_in=gnn_layer(c_in, c_hidd, heads=heads)\n",
    "            \n",
    "            \n",
    "        res_blocks=[]\n",
    "        for size_block in num_blocks:\n",
    "            res_blocks.append(self._make_layer(block, size_block))\n",
    "        self.res_blocks=nn.ModuleList(*res_blocks)\n",
    "        \n",
    "        #out layer of the GATResNet\n",
    "        self.layer_out=gnn_layer(c_hidd*heads, c_out, heads=1)\n",
    "        \n",
    "        \n",
    "    def _make_layer(self, block, num_layers):\n",
    "        layers=[]\n",
    "        for num_layer in range(num_layers):\n",
    "            layers.append(block(\n",
    "                self.c_hidd*self.heads,\n",
    "                self.c_hidd,\n",
    "                heads=self.heads\n",
    "            ))\n",
    "        return nn.ModuleList(layers)#nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        out = self.layer_in(x, edge_index)\n",
    "        for layer in self.res_blocks:\n",
    "            #for layer in block:\n",
    "            out = layer(out, edge_index) \n",
    "        out = self.layer_out(out, edge_index)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba83a93-0209-4074-9008-d1390ab3aa90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InitialEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, c_out, init_method='kaiming'):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(c_in, c_out)\n",
    "        self.embedding = nn.Embedding(11, 3)\n",
    "        self.init_method = init_method\n",
    "        \n",
    "    def _init_parameters(self):\n",
    "            for layer in [*self.fc, self.embedding]:\n",
    "                if self.init_method == 'xavier':\n",
    "                    if isinstance(layer, nn.Linear):\n",
    "                        nn.init.xavier_uniform_(layer.weight)\n",
    "                elif self.init_method == 'kaiming':\n",
    "                    if isinstance(layer, nn.Linear):\n",
    "                        nn.init.kaiming_uniform_(layer.weight, mode='fan_in')\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "        \n",
    "    def forward(self, x, rbf_ij, z):\n",
    "        z = self.embedding(torch.tensor(z))\n",
    "        x = torch.cat((x, rbf_ij, z), 1)\n",
    "        out = F.relu(self.fc(x.float()))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58adb64a-e1f8-403f-a604-169b70dfae79",
   "metadata": {},
   "source": [
    "test linear transformation on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "317dd6d8-4a86-404c-ba60-703e0db977dd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 hidden_channels, \n",
    "                 out_channels,\n",
    "                 in_heads=1,\n",
    "                 out_heads=1,\n",
    "                 num_layers=4, \n",
    "                 layer_name='GAT', \n",
    "                 dp_rate=0.1, \n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.dp_rate = dp_rate\n",
    "        self.hid = hidden_channels\n",
    "        self.in_head = in_heads\n",
    "        self.out_head = out_heads\n",
    "        #c_hidden = self.hid\n",
    "        gnn_layer = gnn_layers[layer_name]\n",
    "        all_layers = []\n",
    "        \n",
    "        for i in range(num_layers - 1):\n",
    "            all_layers += [\n",
    "                gnn_layer(\n",
    "                in_channels, self.hid,\n",
    "                heads=self.in_head, \n",
    "                dropout=self.dp_rate),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(),\n",
    "                ]\n",
    "            in_channels = self.hid*self.in_head\n",
    "            \n",
    "        \n",
    "        all_layers += [\n",
    "            gnn_layer(\n",
    "                self.hid*self.in_head, \n",
    "                out_channels,\n",
    "                heads=self.out_head)\n",
    "                      ]\n",
    "        \n",
    "        self.layers = nn.ModuleList(all_layers)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, geom_nn.MessagePassing):\n",
    "                x = layer(x, edge_index)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9cf959b1-e032-4e49-a022-f03e540d1bc6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 gnn_layer : str,\n",
    "                 in_channels, \n",
    "                 hidden_channels, \n",
    "                 out_channels,\n",
    "                 in_heads=1,\n",
    "                 out_heads=1,\n",
    "                 num_layers=4, \n",
    "                 dp_rate=0.1, \n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dp_rate = dp_rate\n",
    "        self.in_head = in_heads\n",
    "        \n",
    "        \n",
    "        all_layers = []\n",
    "        for i in range(num_layers - 1):\n",
    "            all_layers += [\n",
    "                self._type_layer(\n",
    "                    gnn_layer,\n",
    "                    in_channels,\n",
    "                    hidden_channels,\n",
    "                    heads=in_heads\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(),\n",
    "            ]\n",
    "            if gnn_layer == 'GCN':\n",
    "                in_channels = hidden_channels\n",
    "            else:\n",
    "                in_channels = hidden_channels*self.in_head \n",
    "        \n",
    "        if gnn_layer == 'GCN':\n",
    "            all_layers += [\n",
    "                self._type_layer(\n",
    "                    gnn_layer,\n",
    "                    hidden_channels, \n",
    "                    out_channels,\n",
    "                    heads=None\n",
    "                )\n",
    "            ]\n",
    "        else:\n",
    "            all_layers += [\n",
    "                self._type_layer(\n",
    "                    gnn_layer,\n",
    "                    hidden_channels*self.in_head, \n",
    "                    out_channels,\n",
    "                    heads=out_heads\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        self.layers = nn.ModuleList(all_layers)\n",
    "        \n",
    "    def _type_layer(self, type_gnn : str, c_in, c_out, **kwargs):\n",
    "        \n",
    "        if type_gnn == 'GCN':\n",
    "            gnn_layer = geom_nn.GCNConv(\n",
    "                c_in,\n",
    "                c_out\n",
    "            )\n",
    "        elif type_gnn == 'GAT':\n",
    "            gnn_layer = geom_nn.GATConv(\n",
    "                c_in,\n",
    "                c_out,\n",
    "                heads=heads,\n",
    "                dropout=self.dp_rate,\n",
    "            )\n",
    "        elif type_gnn == 'GATv2':\n",
    "            gnn_layer = geom_nn.GATv2Conv(\n",
    "                c_in,\n",
    "                c_out,\n",
    "                heads=heads,\n",
    "                dropout=self.dp_rate\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        return gnn_layer\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, geom_nn.MessagePassing):\n",
    "                x = layer(x, edge_index)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2919060f-0567-4de6-b751-472b74da3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 in_channels, \n",
    "                 hidden_channels, \n",
    "                 out_channels,\n",
    "                 in_heads=1,\n",
    "                 num_layers=4, \n",
    "                 dp_rate=0.1, \n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        all_layers = []\n",
    "        for i in range(num_layers - 1):\n",
    "            all_layers += [\n",
    "                geom_nn.GATv2Conv(\n",
    "                    in_channels,\n",
    "                    hidden_channels,\n",
    "                    heads=in_heads\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                #nn.Dropout(),\n",
    "            ]\n",
    "            in_channels = hidden_channels*in_heads \n",
    "            \n",
    "        all_layers += [\n",
    "                geom_nn.GATv2Conv(\n",
    "                    hidden_channels*in_heads,\n",
    "                    out_channels,\n",
    "                ),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout()\n",
    "        ]\n",
    "\n",
    "        self.layers = nn.ModuleList(all_layers)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, geom_nn.MessagePassing):\n",
    "                x = layer(x, edge_index)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff739769-e105-4bea-8652-4a0db405f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDGAT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 c_in_embedding,\n",
    "                 c_out_embedding,\n",
    "                 c_hidd_gat,\n",
    "                 c_out_gat,\n",
    "                 heads,\n",
    "                 num_gnn_layers : int = 5,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        #computing the pdists for QM9 dataset\n",
    "        self.pwise_dists = GraphData(n_neighbors=10, radius=10)\n",
    "        \n",
    "        #initial_embedding\n",
    "        self.initial_embedding = InitialEmbedding(\n",
    "            c_in_embedding,\n",
    "            c_out_embedding,\n",
    "            init_method='kaiming',\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.GATModel = GNNModel(\n",
    "                in_channels=c_out_embedding,\n",
    "                hidden_channels=c_hidd_gat,\n",
    "                out_channels=c_out_gat,\n",
    "                in_heads=heads,\n",
    "                num_layers=num_gnn_layers,\n",
    "            )\n",
    "        \n",
    "        self.fc1 = nn.Linear(c_out_gat, c_out_gat*2)\n",
    "        self.out = nn.Linear(c_out_gat*2, 1)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        #batch, x, edge_index, r_ij, z = (\n",
    "         #   data.batch, data.atom_type, data.edge_index, data.r_ij, data.z)\n",
    "        \n",
    "        batch, x, edge_index, pos, z = (\n",
    "            data.batch, data.x, data.edge_index, data.pos, data.z)\n",
    "        \n",
    "        #pairwise distances for qm9\n",
    "        r_ij, _ = self.pwise_dists.pairwise_dists(pos.cpu().numpy())\n",
    "        \n",
    "        r_ij = torch.tensor(r_ij).to(device)\n",
    "        \n",
    "        x = self.initial_embedding(x, r_ij, z)\n",
    "        \n",
    "        x = self.GATModel(x, edge_index)\n",
    "        \n",
    "        x = geom_nn.global_add_pool(x, batch)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        output = self.out(x)\n",
    "        \n",
    "        return output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc1e1a-6fc7-4764-a4b6-e0a6927eb5f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "        graph_data = self.graphData(\n",
    "            atomic_coords[0].float(),\n",
    "            elements,\n",
    "        )\n",
    "        edge_attr = self.rbf(graph_data.r_ij).view(\n",
    "            graph_data.num_nodes, -1)\n",
    "        \n",
    "        node_feature = torch.cat(\n",
    "            (graph_data.atom_type, edge_attr), 1\n",
    "        )\n",
    "        \n",
    "        node_feature = self.transformer(node_feature.float())\n",
    "                \n",
    "        #the layer for converting data to graphs\n",
    "        self.graphData = GraphData(\n",
    "            n_neighbors=30,\n",
    "            radius=10,\n",
    "        )\n",
    "        \n",
    "        #expansion of pairwise distances\n",
    "        self.rbf = RBFExpansion(gap=0.2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6dc308-1ef7-4f41-8c8d-e5258c3e47f0",
   "metadata": {},
   "source": [
    "test of MDGAT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9542f-232c-4e27-9aa3-58d8ffa2dbd7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MDGAT_model = MDGAT(c_in=149, c_hidd=500, c_out=200)\n",
    "\n",
    "y_pred = MDGAT_model(atomic_coords, elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10177a-9745-4ab4-93c9-0becb4bceab1",
   "metadata": {},
   "source": [
    "convert all atomic dataset to graphs with y values as energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2627f105-6f65-4c3d-b3c5-8d05caf299ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_graph = GraphData(n_neighbors=30, radius=10)\n",
    "\n",
    "peptide_graphData = []\n",
    "for i in range(0, len(peptide_dataset)):\n",
    "    peptide_graphData.append(\n",
    "        make_graph(\n",
    "            peptide_dataset[i]['trajectory'], \n",
    "            peptide_dataset[i]['elements'],\n",
    "            peptide_dataset[i]['z'],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0fb7c180-6a08-45b6-be56-03597774989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph, data in \\\n",
    "zip(peptide_graphData, peptide_dataset):\n",
    "    graph.y = torch.mul(data['energy'], 27.2114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7a733ea5-40b7-4842-97fe-dbd23d81af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand rij distances \n",
    "rbf = RBFExpansion(gap=0.4)\n",
    "\n",
    "for graph in peptide_graphData:\n",
    "    graph.r_ij = rbf(graph.r_ij, minmax=True, \n",
    "                     standardScaler=False).view(graph.num_nodes, -1)\n",
    "    graph.x = torch.cat(\n",
    "        (graph.r_ij, graph.atom_type),\n",
    "        1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d144274c-c3c3-4148-bf33-3cca8394acd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-39128.8828])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_graphData[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d2527-7d5c-4848-918a-1248bb976ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f45ff-f109-47f6-a00d-769341a5c5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f059764f-1167-4cfe-8367-d15a4b8c5441",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "56b4f9da-cbf7-49a6-8744-622dfda6a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_gp in optimizer.param_groups:\n",
    "        lr = param_gp['lr']\n",
    "        print(f'learning rate :{lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b2ffe6f0-464c-4058-b262-2acafa21e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 100\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e97695ac-128e-4e0b-b114-95a38af737f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4108"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(peptide_graphData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8def9cd5-b753-4324-9faf-a66a7495c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = torch.utils.data.random_split(\n",
    "    peptide_graphData, \n",
    "    [3000, 1108], \n",
    "    generator=torch.Generator().manual_seed(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8877f770-1369-4a43-9233-1835501613c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = geom_data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "\n",
    "test_loader = geom_data.DataLoader(test_data, batch_size)\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b34b0bd-33c3-48c6-9f31-7eeaa5d931c9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-39127.6836],\n",
       "        [-39127.5820],\n",
       "        [-39128.3594],\n",
       "        [-39128.1172],\n",
       "        [-39127.3555],\n",
       "        [-39128.3672],\n",
       "        [-39128.5273],\n",
       "        [-39127.7695],\n",
       "        [-39128.3516],\n",
       "        [-39127.5781],\n",
       "        [-39127.5312],\n",
       "        [-39128.6016],\n",
       "        [-39127.6484],\n",
       "        [-39128.2930],\n",
       "        [-39128.0625],\n",
       "        [-39128.6641],\n",
       "        [-39128.0430],\n",
       "        [-39127.6250],\n",
       "        [-39128.0625],\n",
       "        [-39128.3867],\n",
       "        [-39128.3359],\n",
       "        [-39128.0195],\n",
       "        [-39128.1016],\n",
       "        [-39127.3320],\n",
       "        [-39127.9609],\n",
       "        [-39127.7891],\n",
       "        [-39127.6016],\n",
       "        [-39128.0547],\n",
       "        [-39127.5430],\n",
       "        [-39128.1016],\n",
       "        [-39127.4297],\n",
       "        [-39128.6211],\n",
       "        [-39128.3516],\n",
       "        [-39127.8672],\n",
       "        [-39128.4414],\n",
       "        [-39127.9414],\n",
       "        [-39128.3906],\n",
       "        [-39127.9492],\n",
       "        [-39127.4141],\n",
       "        [-39128.0703],\n",
       "        [-39128.0938],\n",
       "        [-39127.6445],\n",
       "        [-39128.4609],\n",
       "        [-39128.5859],\n",
       "        [-39128.1094],\n",
       "        [-39127.8125],\n",
       "        [-39128.1328],\n",
       "        [-39127.7227],\n",
       "        [-39127.8398],\n",
       "        [-39127.7109],\n",
       "        [-39127.7539],\n",
       "        [-39127.7461],\n",
       "        [-39128.8164],\n",
       "        [-39127.4453],\n",
       "        [-39128.5977],\n",
       "        [-39127.7383],\n",
       "        [-39128.6797],\n",
       "        [-39127.9648],\n",
       "        [-39128.0156],\n",
       "        [-39128.4922],\n",
       "        [-39128.0000],\n",
       "        [-39127.7852],\n",
       "        [-39128.5156],\n",
       "        [-39127.4688],\n",
       "        [-39128.5586],\n",
       "        [-39127.9219],\n",
       "        [-39128.0703],\n",
       "        [-39128.0547],\n",
       "        [-39128.0977],\n",
       "        [-39128.6562],\n",
       "        [-39128.3867],\n",
       "        [-39127.9453],\n",
       "        [-39127.8477],\n",
       "        [-39128.1445],\n",
       "        [-39127.9766],\n",
       "        [-39127.9844],\n",
       "        [-39128.5703],\n",
       "        [-39127.2188],\n",
       "        [-39128.3125],\n",
       "        [-39128.4062],\n",
       "        [-39127.5586],\n",
       "        [-39127.9141],\n",
       "        [-39128.2539],\n",
       "        [-39127.3359],\n",
       "        [-39127.7734],\n",
       "        [-39128.2617],\n",
       "        [-39127.8906],\n",
       "        [-39128.0820],\n",
       "        [-39128.1562],\n",
       "        [-39128.5352],\n",
       "        [-39128.1797],\n",
       "        [-39127.4805],\n",
       "        [-39127.2031],\n",
       "        [-39127.8906],\n",
       "        [-39127.5938],\n",
       "        [-39128.5664],\n",
       "        [-39128.4219],\n",
       "        [-39128.4414],\n",
       "        [-39128.1992],\n",
       "        [-39128.0938]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32f694cf-f3f4-4534-8ef9-8eae8d30c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3520d7b-b831-4100-b539-e530828877ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0,1,2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1205974-d8c2-43ab-9a9e-b47182af1c2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setting up TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b9c0bfd-b2f2-42da-88b2-928a581c2cf6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "run_num = 1\n",
    "\n",
    "writer = SummaryWriter(f'runs/MDGNN_experiment{run_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "eda41fac-7672-4849-ae14-83c90208508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDGAT_model = MDGAT(\n",
    "    c_in_embedding=94,\n",
    "    c_out_embedding=94,\n",
    "    c_hidd_gat=256,\n",
    "    c_out_gat=128,\n",
    "    heads=5,\n",
    "    num_gnn_layers=4\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "47b56b48-b28a-4698-9142-1fc71827179b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDGAT(\n",
       "  (initial_embedding): InitialEmbedding(\n",
       "    (fc): Linear(in_features=94, out_features=94, bias=True)\n",
       "    (embedding): Embedding(11, 3)\n",
       "  )\n",
       "  (GATModel): GNNModel(\n",
       "    (layers): ModuleList(\n",
       "      (0): GATv2Conv(94, 128, heads=5)\n",
       "      (1): ReLU()\n",
       "      (2): GATv2Conv(640, 128, heads=5)\n",
       "      (3): ReLU()\n",
       "      (4): GATv2Conv(640, 128, heads=5)\n",
       "      (5): ReLU()\n",
       "      (6): GATv2Conv(640, 56, heads=1)\n",
       "      (7): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=56, out_features=112, bias=True)\n",
       "  (out): Linear(in_features=112, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MDGAT_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "15153e7b-d3b1-4ac1-bb6f-1d2ad4795fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MDGAT_model = nn.DataParallel(MDGAT_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6e29514e-ffbd-4e71-be9c-19d70218e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = nn.MSELoss().to(device)\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(MDGAT_model.parameters(), learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',\n",
    "    patience=20,\n",
    "    factor=0.85,\n",
    "    min_lr=1e-7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bbd4e9a6-b7ea-44a8-8b5d-c3e2f9d7780e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 806.00 MiB (GPU 3; 15.90 GiB total capacity; 14.09 GiB already allocated; 533.56 MiB free; 14.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [182]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     21\u001b[0m     batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 22\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mMDGAT_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(\n\u001b[1;32m     24\u001b[0m          output,batch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     25\u001b[0m     val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/beegfs/desy/user/kotobiam/venv_geopytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [172]\u001b[0m, in \u001b[0;36mMDGAT.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     32\u001b[0m batch, x, edge_index, r_ij, z \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     33\u001b[0m     data\u001b[38;5;241m.\u001b[39mbatch, data\u001b[38;5;241m.\u001b[39matom_type, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39mr_ij, data\u001b[38;5;241m.\u001b[39mz)\n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_embedding(x, r_ij, z)\n\u001b[0;32m---> 37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGATModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m geom_nn\u001b[38;5;241m.\u001b[39mglobal_add_pool(x, batch)\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n",
      "File \u001b[0;32m/beegfs/desy/user/kotobiam/venv_geopytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [171]\u001b[0m, in \u001b[0;36mGNNModel.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, geom_nn\u001b[38;5;241m.\u001b[39mMessagePassing):\n\u001b[0;32m---> 40\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x)\n",
      "File \u001b[0;32m/beegfs/desy/user/kotobiam/venv_geopytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/beegfs/desy/user/kotobiam/venv_geopytorch/lib/python3.8/site-packages/torch_geometric/nn/conv/gatv2_conv.py:235\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe usage of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_self_loops\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimultaneously is currently not yet supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseTensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m form\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: PairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_r\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alpha\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/beegfs/desy/user/kotobiam/venv_geopytorch/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:317\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 317\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    319\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m/beegfs/desy/user/kotobiam/venv_geopytorch/lib/python3.8/site-packages/torch_geometric/nn/conv/gatv2_conv.py:261\u001b[0m, in \u001b[0;36mGATv2Conv.message\u001b[0;34m(self, x_j, x_i, edge_attr, index, ptr, size_i)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, x_i: Tensor, edge_attr: OptTensor,\n\u001b[1;32m    259\u001b[0m             index: Tensor, ptr: OptTensor,\n\u001b[1;32m    260\u001b[0m             size_i: Optional[\u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 261\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_j\u001b[49m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m edge_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m edge_attr\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 806.00 MiB (GPU 3; 15.90 GiB total capacity; 14.09 GiB already allocated; 533.56 MiB free; 14.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for total_epochs in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    total_graphs = 0\n",
    "    MDGAT_model.train()\n",
    "    for batch in train_loader:\n",
    "        batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = MDGAT_model(batch)\n",
    "        loss = loss_fn(\n",
    "             output,batch.y.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        total_graphs += batch.num_graphs\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch_loss)\n",
    "    train_avg_loss = epoch_loss / total_graphs\n",
    "    val_loss = 0\n",
    "    total_graphs = 0\n",
    "    MDGAT_model.eval()\n",
    "    for batch in test_loader:\n",
    "        batch.to(device)\n",
    "        output = MDGAT_model(batch)\n",
    "        loss = loss_fn(\n",
    "             output,batch.y.unsqueeze(1))\n",
    "        val_loss += loss.item()\n",
    "        total_graphs += batch.num_graphs\n",
    "    val_avg_loss = val_loss / total_graphs\n",
    "    print(f\"Epochs: {total_epochs} | \"\n",
    "           f\"epoch avg. loss: {train_avg_loss:.2f} | \"\n",
    "           f\"validation avg. loss: {val_avg_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8601162f-682a-4e33-ab12-6a63efe5f3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c94ee-b794-4bdb-940b-42b426c59937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ac58be-1281-4558-b9d7-3f096d90139b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ae86a-a65d-4bbd-9518-a5d892daf985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d0d0591-168c-4697-a1d1-24f68b2d25a4",
   "metadata": {},
   "source": [
    "# Testing the model on different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d3f80-3567-4713-82da-e2c93c710acb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch_geometric.data as geom_data\n",
    "\n",
    "tu_dataset = torch_geometric.datasets.TUDataset(root='./', name=\"MUTAG\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "tu_dataset.shuffle()\n",
    "train_dataset = tu_dataset[:150]\n",
    "test_dataset = tu_dataset[150:]\n",
    "\n",
    "graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "graph_val_loader = geom_data.DataLoader(test_dataset, batch_size=64) # Additional loader if you want to change to a larger dataset\n",
    "graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "batch = next(iter(graph_train_loader))\n",
    "\n",
    "batch\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff65877-c0ad-4647-ae2e-8433fc3a29ae",
   "metadata": {},
   "source": [
    "## QM9 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e5545ef-b901-4053-8e52-dff656f6e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import QM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b37d280-8151-4c85-b041-82403a3accdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9_dataset = QM9(root='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70d5d59a-fe51-4190-951e-fcc9902f66f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test data\n",
    "qm9_dataset.shuffle()\n",
    "\n",
    "train_dataset = qm9_dataset[:20000]\n",
    "test_dataset = qm9_dataset[20001:24000]\n",
    "\n",
    "qm9_train_loader = geom_data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "qm9_test_loader = geom_data.DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6642298-b7f1-4702-b85f-3fc22f9086ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -8860.0137],\n",
       "        [ -7382.6206],\n",
       "        [ -9903.1523],\n",
       "        [-10744.4805],\n",
       "        [ -9238.8115],\n",
       "        [ -7763.8740],\n",
       "        [ -9674.6787],\n",
       "        [-10848.9199],\n",
       "        [ -9132.6865],\n",
       "        [ -7358.4194],\n",
       "        [ -7567.0889],\n",
       "        [ -9438.6230],\n",
       "        [-10340.1572],\n",
       "        [-10411.7070],\n",
       "        [ -8833.9160],\n",
       "        [ -9270.8027],\n",
       "        [ -8832.7744],\n",
       "        [-10383.7637],\n",
       "        [ -9270.7080],\n",
       "        [ -9373.9561],\n",
       "        [ -6753.2163],\n",
       "        [ -8258.3877],\n",
       "        [ -8462.3682],\n",
       "        [ -8293.0977],\n",
       "        [ -8428.7852],\n",
       "        [ -9733.8633],\n",
       "        [ -8799.8926],\n",
       "        [ -8893.3994],\n",
       "        [ -8397.4414],\n",
       "        [-10340.1211],\n",
       "        [ -9811.2695],\n",
       "        [-11859.4648],\n",
       "        [ -8831.9795],\n",
       "        [-10340.0176],\n",
       "        [ -8494.5625],\n",
       "        [ -9302.7168],\n",
       "        [ -9438.2930],\n",
       "        [ -9316.0850],\n",
       "        [ -7418.1787],\n",
       "        [ -9372.0371],\n",
       "        [ -8697.8379],\n",
       "        [ -8428.2998],\n",
       "        [ -9362.2236],\n",
       "        [ -9399.9258],\n",
       "        [ -9439.7090],\n",
       "        [-11317.6123],\n",
       "        [ -8395.9893],\n",
       "        [ -8261.1533],\n",
       "        [ -7417.5151],\n",
       "        [ -8336.2354],\n",
       "        [ -8338.3672],\n",
       "        [-11317.8750],\n",
       "        [ -9892.2354],\n",
       "        [-10338.5059],\n",
       "        [ -8324.9863],\n",
       "        [ -8729.1973],\n",
       "        [ -9903.1094],\n",
       "        [ -9380.3047],\n",
       "        [ -9347.0352],\n",
       "        [-10877.7178],\n",
       "        [ -8865.9521],\n",
       "        [ -8289.0176],\n",
       "        [ -8427.8594],\n",
       "        [-10275.1162]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(qm9_train_loader))\n",
    "batch.y[:, 10].unsqueeze(1)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0ad238ed-0a3f-4aa1-a4bd-d7625eb40ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MDGAT_model = MDGAT(\n",
    "    c_in_embedding=24,\n",
    "    c_out_embedding=24,\n",
    "    c_hidd_gat=256,\n",
    "    c_out_gat=128,\n",
    "    heads=8,\n",
    "    num_gnn_layers=7\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c34c4623-bb4b-4efc-82d8-70a8bb9faeeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loss_fn = nn.MSELoss().to(device)\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(MDGAT_model.parameters(), 1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',\n",
    "    patience=20,\n",
    "    factor=0.85,\n",
    "    min_lr=1e-7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "12aec07e-dac6-444f-964d-181c96933633",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0 | epoch avg. loss: 20.67 | validation avg. loss: 9.74\n",
      "Epochs: 1 | epoch avg. loss: 3.58 | validation avg. loss: 5.94\n",
      "Epochs: 2 | epoch avg. loss: 2.80 | validation avg. loss: 5.58\n",
      "Epochs: 3 | epoch avg. loss: 2.71 | validation avg. loss: 5.75\n",
      "Epochs: 4 | epoch avg. loss: 2.70 | validation avg. loss: 5.66\n",
      "Epochs: 5 | epoch avg. loss: 2.70 | validation avg. loss: 5.69\n",
      "Epochs: 6 | epoch avg. loss: 2.70 | validation avg. loss: 5.64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m output \u001b[38;5;241m=\u001b[39m MDGAT_model(batch)\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(\n\u001b[1;32m     10\u001b[0m      output,batch\u001b[38;5;241m.\u001b[39my[:, \u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 11\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     13\u001b[0m total_graphs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mnum_graphs\n",
      "File \u001b[0;32m/beegfs/desy/user/kotobiam/venv_geopytorch/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/beegfs/desy/user/kotobiam/venv_geopytorch/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for total_epochs in range(100):\n",
    "    epoch_loss = 0\n",
    "    total_graphs = 0\n",
    "    MDGAT_model.train()\n",
    "    for batch in qm9_train_loader:\n",
    "        batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = MDGAT_model(batch)\n",
    "        loss = loss_fn(\n",
    "             output,batch.y[:, 10].unsqueeze(1))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        total_graphs += batch.num_graphs\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch_loss)\n",
    "    train_avg_loss = epoch_loss / total_graphs\n",
    "    val_loss = 0\n",
    "    total_graphs = 0\n",
    "    MDGAT_model.eval()\n",
    "    for batch in qm9_test_loader:\n",
    "        batch.to(device)\n",
    "        output = MDGAT_model(batch)\n",
    "        loss = loss_fn(\n",
    "             output,batch.y[:, 10].unsqueeze(1))\n",
    "        val_loss += loss.item()\n",
    "        total_graphs += batch.num_graphs\n",
    "    val_avg_loss = val_loss / total_graphs\n",
    "    print(f\"Epochs: {total_epochs} | \"\n",
    "           f\"epoch avg. loss: {train_avg_loss:.2f} | \"\n",
    "           f\"validation avg. loss: {val_avg_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e894f9-b7c6-4b9c-b4f9-22cf3bec21c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ce8d198-99e8-4676-aa83-08896fbc605e",
   "metadata": {},
   "source": [
    "# Using Pytorch lightning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b62aa765-d0af-42f8-9776-43da40fa91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4723d08d-ea9d-4635-8d91-a7e06bfc41c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMDGNN(pl.LightningModule):\n",
    "    def __init__(self, gnn_model):\n",
    "        super().__init__()\n",
    "        self.gnn_model = gnn_model\n",
    "        self.save_hyperparameters()\n",
    "                \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        output = self.gnn_model(batch)\n",
    "        loss = loss_fn(output, batch.y[:, 10].unsqueeze(1))\n",
    "        return loss / batch.num_graphs\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        output = self.gnn_model(batch)\n",
    "        test_loss = loss_fn(output, batch.y[:, 10].unsqueeze(1))\n",
    "        self.log(\"test_loss\", test_loss / batch.num_graphs)\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        output = self.gnn_model(batch)\n",
    "        test_loss = loss_fn(output, batch.y[:, 10].unsqueeze(1))\n",
    "        self.log(\"val_loss\", test_loss / batch.num_graphs)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), \n",
    "            1e-3\n",
    "        )\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c8bf7a77-0135-4fbc-9744-8912bd802ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDGAT_model = MDGAT(\n",
    "    c_in_embedding=24,\n",
    "    c_out_embedding=24,\n",
    "    c_hidd_gat=128,\n",
    "    c_out_gat=56,\n",
    "    heads=5,\n",
    "    num_gnn_layers=4\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc920bf5-4d85-4ed3-b1d6-5638b8552130",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = int(len(train_dataset)*0.8)\n",
    "val_set_size = len(train_dataset) - train_set_size\n",
    "\n",
    "seed=torch.Generator().manual_seed(42)\n",
    "train_data, val_data = random_split(train_dataset, \n",
    "                                    [train_set_size, val_set_size],\n",
    "                                    seed)\n",
    "\n",
    "qm9_train_loader = geom_data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "qm9_val_loader = geom_data.DataLoader(val_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686d5808-3392-4dae-88be-0dccb01c2e4a",
   "metadata": {},
   "source": [
    "## early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3f8fad4d-5f85-475f-bd65-19b253f5c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callbacks = EarlyStopping(monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2a52db52-aa00-4de4-82f0-9fff9662b95b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type  | Params\n",
      "------------------------------------\n",
      "0 | gnn_model | MDGAT | 1.8 M \n",
      "------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80%|███████▉  | 250/313 [00:09<00:02, 27.09it/s, loss=2.2, v_num=1.21e+7] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 251/313 [00:09<00:02, 27.12it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  81%|████████  | 252/313 [00:09<00:02, 27.16it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  81%|████████  | 253/313 [00:09<00:02, 27.20it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  81%|████████  | 254/313 [00:09<00:02, 27.25it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  81%|████████▏ | 255/313 [00:09<00:02, 27.29it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  82%|████████▏ | 256/313 [00:09<00:02, 27.33it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  82%|████████▏ | 257/313 [00:09<00:02, 27.38it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  82%|████████▏ | 258/313 [00:09<00:02, 27.42it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  83%|████████▎ | 259/313 [00:09<00:01, 27.47it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  83%|████████▎ | 260/313 [00:09<00:01, 27.51it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  83%|████████▎ | 261/313 [00:09<00:01, 27.55it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  84%|████████▎ | 262/313 [00:09<00:01, 27.59it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  84%|████████▍ | 263/313 [00:09<00:01, 27.63it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  84%|████████▍ | 264/313 [00:09<00:01, 27.67it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  85%|████████▍ | 265/313 [00:09<00:01, 27.71it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  85%|████████▍ | 266/313 [00:09<00:01, 27.75it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  85%|████████▌ | 267/313 [00:09<00:01, 27.80it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  86%|████████▌ | 268/313 [00:09<00:01, 27.84it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  86%|████████▌ | 269/313 [00:09<00:01, 27.88it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  86%|████████▋ | 270/313 [00:09<00:01, 27.91it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  87%|████████▋ | 271/313 [00:09<00:01, 27.95it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  87%|████████▋ | 272/313 [00:09<00:01, 27.99it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  87%|████████▋ | 273/313 [00:09<00:01, 28.03it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  88%|████████▊ | 274/313 [00:09<00:01, 28.07it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  88%|████████▊ | 275/313 [00:09<00:01, 28.11it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  88%|████████▊ | 276/313 [00:09<00:01, 28.15it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  88%|████████▊ | 277/313 [00:09<00:01, 28.19it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  89%|████████▉ | 278/313 [00:09<00:01, 28.23it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  89%|████████▉ | 279/313 [00:09<00:01, 28.27it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  89%|████████▉ | 280/313 [00:09<00:01, 28.31it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  90%|████████▉ | 281/313 [00:09<00:01, 28.35it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  90%|█████████ | 282/313 [00:09<00:01, 28.38it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  90%|█████████ | 283/313 [00:09<00:01, 28.42it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  91%|█████████ | 284/313 [00:09<00:01, 28.46it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  91%|█████████ | 285/313 [00:10<00:00, 28.50it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  91%|█████████▏| 286/313 [00:10<00:00, 28.54it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  92%|█████████▏| 287/313 [00:10<00:00, 28.57it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  92%|█████████▏| 288/313 [00:10<00:00, 28.61it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  92%|█████████▏| 289/313 [00:10<00:00, 28.65it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  93%|█████████▎| 290/313 [00:10<00:00, 28.68it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  93%|█████████▎| 291/313 [00:10<00:00, 28.72it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  93%|█████████▎| 292/313 [00:10<00:00, 28.76it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  94%|█████████▎| 293/313 [00:10<00:00, 28.79it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  94%|█████████▍| 294/313 [00:10<00:00, 28.83it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  94%|█████████▍| 295/313 [00:10<00:00, 28.86it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  95%|█████████▍| 296/313 [00:10<00:00, 28.90it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  95%|█████████▍| 297/313 [00:10<00:00, 28.93it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  95%|█████████▌| 298/313 [00:10<00:00, 28.97it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  96%|█████████▌| 299/313 [00:10<00:00, 29.00it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  96%|█████████▌| 300/313 [00:10<00:00, 29.04it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  96%|█████████▌| 301/313 [00:10<00:00, 29.07it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  96%|█████████▋| 302/313 [00:10<00:00, 29.11it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  97%|█████████▋| 303/313 [00:10<00:00, 29.14it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  97%|█████████▋| 304/313 [00:10<00:00, 29.18it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  97%|█████████▋| 305/313 [00:10<00:00, 29.21it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  98%|█████████▊| 306/313 [00:10<00:00, 29.25it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  98%|█████████▊| 307/313 [00:10<00:00, 29.28it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  98%|█████████▊| 308/313 [00:10<00:00, 29.31it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  99%|█████████▊| 309/313 [00:10<00:00, 29.35it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  99%|█████████▉| 310/313 [00:10<00:00, 29.38it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0:  99%|█████████▉| 311/313 [00:10<00:00, 29.41it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0: 100%|█████████▉| 312/313 [00:10<00:00, 29.45it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 0: 100%|██████████| 313/313 [00:10<00:00, 29.49it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 1:  80%|███████▉  | 250/313 [00:09<00:02, 27.58it/s, loss=2.37, v_num=1.21e+7]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 251/313 [00:09<00:02, 27.60it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  81%|████████  | 252/313 [00:09<00:02, 27.64it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  81%|████████  | 253/313 [00:09<00:02, 27.68it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  81%|████████  | 254/313 [00:09<00:02, 27.72it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  81%|████████▏ | 255/313 [00:09<00:02, 27.76it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  82%|████████▏ | 256/313 [00:09<00:02, 27.80it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  82%|████████▏ | 257/313 [00:09<00:02, 27.84it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  82%|████████▏ | 258/313 [00:09<00:01, 27.88it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  83%|████████▎ | 259/313 [00:09<00:01, 27.92it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  83%|████████▎ | 260/313 [00:09<00:01, 27.96it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  83%|████████▎ | 261/313 [00:09<00:01, 28.00it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  84%|████████▎ | 262/313 [00:09<00:01, 28.05it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  84%|████████▍ | 263/313 [00:09<00:01, 28.08it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  84%|████████▍ | 264/313 [00:09<00:01, 28.13it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  85%|████████▍ | 265/313 [00:09<00:01, 28.17it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  85%|████████▍ | 266/313 [00:09<00:01, 28.21it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  85%|████████▌ | 267/313 [00:09<00:01, 28.25it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  86%|████████▌ | 268/313 [00:09<00:01, 28.29it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  86%|████████▌ | 269/313 [00:09<00:01, 28.33it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  86%|████████▋ | 270/313 [00:09<00:01, 28.37it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  87%|████████▋ | 271/313 [00:09<00:01, 28.41it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  87%|████████▋ | 272/313 [00:09<00:01, 28.45it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  87%|████████▋ | 273/313 [00:09<00:01, 28.49it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  88%|████████▊ | 274/313 [00:09<00:01, 28.53it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  88%|████████▊ | 275/313 [00:09<00:01, 28.57it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  88%|████████▊ | 276/313 [00:09<00:01, 28.61it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  88%|████████▊ | 277/313 [00:09<00:01, 28.65it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  89%|████████▉ | 278/313 [00:09<00:01, 28.69it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  89%|████████▉ | 279/313 [00:09<00:01, 28.72it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  89%|████████▉ | 280/313 [00:09<00:01, 28.76it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  90%|████████▉ | 281/313 [00:09<00:01, 28.80it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  90%|█████████ | 282/313 [00:09<00:01, 28.84it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  90%|█████████ | 283/313 [00:09<00:01, 28.88it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  91%|█████████ | 284/313 [00:09<00:01, 28.92it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  91%|█████████ | 285/313 [00:09<00:00, 28.96it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  91%|█████████▏| 286/313 [00:09<00:00, 29.00it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  92%|█████████▏| 287/313 [00:09<00:00, 29.03it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  92%|█████████▏| 288/313 [00:09<00:00, 29.07it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  92%|█████████▏| 289/313 [00:09<00:00, 29.11it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  93%|█████████▎| 290/313 [00:09<00:00, 29.14it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  93%|█████████▎| 291/313 [00:09<00:00, 29.18it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  93%|█████████▎| 292/313 [00:09<00:00, 29.22it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  94%|█████████▎| 293/313 [00:10<00:00, 29.25it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  94%|█████████▍| 294/313 [00:10<00:00, 29.29it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  94%|█████████▍| 295/313 [00:10<00:00, 29.33it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  95%|█████████▍| 296/313 [00:10<00:00, 29.36it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  95%|█████████▍| 297/313 [00:10<00:00, 29.40it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  95%|█████████▌| 298/313 [00:10<00:00, 29.43it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  96%|█████████▌| 299/313 [00:10<00:00, 29.47it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  96%|█████████▌| 300/313 [00:10<00:00, 29.51it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  96%|█████████▌| 301/313 [00:10<00:00, 29.54it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  96%|█████████▋| 302/313 [00:10<00:00, 29.57it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  97%|█████████▋| 303/313 [00:10<00:00, 29.61it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  97%|█████████▋| 304/313 [00:10<00:00, 29.64it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  97%|█████████▋| 305/313 [00:10<00:00, 29.68it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  98%|█████████▊| 306/313 [00:10<00:00, 29.71it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  98%|█████████▊| 307/313 [00:10<00:00, 29.75it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  98%|█████████▊| 308/313 [00:10<00:00, 29.78it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  99%|█████████▊| 309/313 [00:10<00:00, 29.81it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  99%|█████████▉| 310/313 [00:10<00:00, 29.85it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1:  99%|█████████▉| 311/313 [00:10<00:00, 29.88it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1: 100%|█████████▉| 312/313 [00:10<00:00, 29.91it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 1: 100%|██████████| 313/313 [00:10<00:00, 29.96it/s, loss=2.37, v_num=1.21e+7]\n",
      "Epoch 2:  35%|███▌      | 111/313 [00:03<00:07, 28.55it/s, loss=2.47, v_num=1.21e+7]"
     ]
    }
   ],
   "source": [
    "gat_model = LitMDGNN(MDGAT_model)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1, \n",
    "    max_epochs=100, \n",
    "    callbacks=[early_stopping_callbacks],\n",
    ")\n",
    "\n",
    "trainer.fit(gat_model, qm9_train_loader, qm9_val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e987d-29a0-4d7a-9a8b-07ccc9ded3a9",
   "metadata": {},
   "source": [
    "## debugging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9d2d0d07-495c-4836-8c0a-1e2509706ca4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 10 batch(es). Logging and checkpointing is suppressed.\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type  | Params\n",
      "------------------------------------\n",
      "0 | gnn_model | MDGAT | 1.8 M \n",
      "------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 10/20 [00:00<00:00, 27.23it/s, loss=7.06, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  55%|█████▌    | 11/20 [00:00<00:00, 27.66it/s, loss=7.06, v_num=]\n",
      "Epoch 0:  60%|██████    | 12/20 [00:00<00:00, 28.50it/s, loss=7.06, v_num=]\n",
      "Epoch 0:  65%|██████▌   | 13/20 [00:00<00:00, 29.21it/s, loss=7.06, v_num=]\n",
      "Epoch 0:  70%|███████   | 14/20 [00:00<00:00, 30.00it/s, loss=7.06, v_num=]\n",
      "Epoch 0:  75%|███████▌  | 15/20 [00:00<00:00, 30.66it/s, loss=7.06, v_num=]\n",
      "Epoch 0:  80%|████████  | 16/20 [00:00<00:00, 31.32it/s, loss=7.06, v_num=]\n",
      "Epoch 0:  85%|████████▌ | 17/20 [00:00<00:00, 31.91it/s, loss=7.06, v_num=]\n",
      "Epoch 0:  90%|█████████ | 18/20 [00:00<00:00, 32.44it/s, loss=7.06, v_num=]\n",
      "Epoch 0:  95%|█████████▌| 19/20 [00:00<00:00, 32.91it/s, loss=7.06, v_num=]\n",
      "Epoch 0: 100%|██████████| 20/20 [00:00<00:00, 33.24it/s, loss=7.06, v_num=]\n",
      "Epoch 0: 100%|██████████| 20/20 [00:00<00:00, 33.10it/s, loss=7.06, v_num=]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 20/20 [00:00<00:00, 33.02it/s, loss=7.06, v_num=]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(fast_dev_run=10, gpus=1)\n",
    "trainer.fit(gat_model, qm9_train_loader, qm9_val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5e64f3-1114-4d96-bf68-d77aeaefc945",
   "metadata": {},
   "source": [
    "## Run a sanity check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cc142572-bf9b-48a8-90b6-5b11784ac3a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type  | Params\n",
      "------------------------------------\n",
      "0 | gnn_model | MDGAT | 1.8 M \n",
      "------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80%|███████▉  | 250/313 [00:08<00:02, 28.04it/s, loss=1.37, v_num=1.21e+7]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 251/313 [00:08<00:02, 28.07it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  81%|████████  | 252/313 [00:08<00:02, 28.11it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  81%|████████  | 253/313 [00:08<00:02, 28.15it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  81%|████████  | 254/313 [00:09<00:02, 28.20it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  81%|████████▏ | 255/313 [00:09<00:02, 28.24it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  82%|████████▏ | 256/313 [00:09<00:02, 28.28it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  82%|████████▏ | 257/313 [00:09<00:01, 28.33it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  82%|████████▏ | 258/313 [00:09<00:01, 28.37it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  83%|████████▎ | 259/313 [00:09<00:01, 28.41it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  83%|████████▎ | 260/313 [00:09<00:01, 28.45it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  83%|████████▎ | 261/313 [00:09<00:01, 28.49it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  84%|████████▎ | 262/313 [00:09<00:01, 28.54it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  84%|████████▍ | 263/313 [00:09<00:01, 28.58it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  84%|████████▍ | 264/313 [00:09<00:01, 28.62it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  85%|████████▍ | 265/313 [00:09<00:01, 28.66it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  85%|████████▍ | 266/313 [00:09<00:01, 28.70it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  85%|████████▌ | 267/313 [00:09<00:01, 28.75it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  86%|████████▌ | 268/313 [00:09<00:01, 28.79it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  86%|████████▌ | 269/313 [00:09<00:01, 28.83it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  86%|████████▋ | 270/313 [00:09<00:01, 28.86it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  87%|████████▋ | 271/313 [00:09<00:01, 28.90it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  87%|████████▋ | 272/313 [00:09<00:01, 28.94it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  87%|████████▋ | 273/313 [00:09<00:01, 28.98it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  88%|████████▊ | 274/313 [00:09<00:01, 29.02it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  88%|████████▊ | 275/313 [00:09<00:01, 29.06it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  88%|████████▊ | 276/313 [00:09<00:01, 29.10it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  88%|████████▊ | 277/313 [00:09<00:01, 29.14it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  89%|████████▉ | 278/313 [00:09<00:01, 29.18it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  89%|████████▉ | 279/313 [00:09<00:01, 29.21it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  89%|████████▉ | 280/313 [00:09<00:01, 29.25it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  90%|████████▉ | 281/313 [00:09<00:01, 29.29it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  90%|█████████ | 282/313 [00:09<00:01, 29.33it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  90%|█████████ | 283/313 [00:09<00:01, 29.37it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  91%|█████████ | 284/313 [00:09<00:00, 29.41it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  91%|█████████ | 285/313 [00:09<00:00, 29.45it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  91%|█████████▏| 286/313 [00:09<00:00, 29.48it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  92%|█████████▏| 287/313 [00:09<00:00, 29.52it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  92%|█████████▏| 288/313 [00:09<00:00, 29.55it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  92%|█████████▏| 289/313 [00:09<00:00, 29.59it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  93%|█████████▎| 290/313 [00:09<00:00, 29.63it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  93%|█████████▎| 291/313 [00:09<00:00, 29.67it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  93%|█████████▎| 292/313 [00:09<00:00, 29.70it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  94%|█████████▎| 293/313 [00:09<00:00, 29.74it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  94%|█████████▍| 294/313 [00:09<00:00, 29.77it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  94%|█████████▍| 295/313 [00:09<00:00, 29.81it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  95%|█████████▍| 296/313 [00:09<00:00, 29.84it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  95%|█████████▍| 297/313 [00:09<00:00, 29.88it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  95%|█████████▌| 298/313 [00:09<00:00, 29.92it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  96%|█████████▌| 299/313 [00:09<00:00, 29.95it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  96%|█████████▌| 300/313 [00:10<00:00, 29.99it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  96%|█████████▌| 301/313 [00:10<00:00, 30.02it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  96%|█████████▋| 302/313 [00:10<00:00, 30.06it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  97%|█████████▋| 303/313 [00:10<00:00, 30.09it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  97%|█████████▋| 304/313 [00:10<00:00, 30.12it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  97%|█████████▋| 305/313 [00:10<00:00, 30.16it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  98%|█████████▊| 306/313 [00:10<00:00, 30.19it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  98%|█████████▊| 307/313 [00:10<00:00, 30.22it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  98%|█████████▊| 308/313 [00:10<00:00, 30.26it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  99%|█████████▊| 309/313 [00:10<00:00, 30.29it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  99%|█████████▉| 310/313 [00:10<00:00, 30.32it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0:  99%|█████████▉| 311/313 [00:10<00:00, 30.36it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0: 100%|█████████▉| 312/313 [00:10<00:00, 30.39it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 0: 100%|██████████| 313/313 [00:10<00:00, 30.44it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 1:  80%|███████▉  | 250/313 [00:09<00:02, 27.62it/s, loss=2.23, v_num=1.21e+7]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 251/313 [00:09<00:02, 27.64it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  81%|████████  | 252/313 [00:09<00:02, 27.68it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  81%|████████  | 253/313 [00:09<00:02, 27.73it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  81%|████████  | 254/313 [00:09<00:02, 27.77it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  81%|████████▏ | 255/313 [00:09<00:02, 27.81it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  82%|████████▏ | 256/313 [00:09<00:02, 27.86it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  82%|████████▏ | 257/313 [00:09<00:02, 27.90it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  82%|████████▏ | 258/313 [00:09<00:01, 27.95it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  83%|████████▎ | 259/313 [00:09<00:01, 27.99it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  83%|████████▎ | 260/313 [00:09<00:01, 28.03it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  83%|████████▎ | 261/313 [00:09<00:01, 28.07it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  84%|████████▎ | 262/313 [00:09<00:01, 28.11it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  84%|████████▍ | 263/313 [00:09<00:01, 28.15it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  84%|████████▍ | 264/313 [00:09<00:01, 28.19it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  85%|████████▍ | 265/313 [00:09<00:01, 28.23it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  85%|████████▍ | 266/313 [00:09<00:01, 28.27it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  85%|████████▌ | 267/313 [00:09<00:01, 28.32it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  86%|████████▌ | 268/313 [00:09<00:01, 28.36it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  86%|████████▌ | 269/313 [00:09<00:01, 28.40it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  86%|████████▋ | 270/313 [00:09<00:01, 28.44it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  87%|████████▋ | 271/313 [00:09<00:01, 28.48it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  87%|████████▋ | 272/313 [00:09<00:01, 28.51it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  87%|████████▋ | 273/313 [00:09<00:01, 28.55it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  88%|████████▊ | 274/313 [00:09<00:01, 28.59it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  88%|████████▊ | 275/313 [00:09<00:01, 28.63it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  88%|████████▊ | 276/313 [00:09<00:01, 28.67it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  88%|████████▊ | 277/313 [00:09<00:01, 28.71it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  89%|████████▉ | 278/313 [00:09<00:01, 28.75it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  89%|████████▉ | 279/313 [00:09<00:01, 28.79it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  89%|████████▉ | 280/313 [00:09<00:01, 28.83it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  90%|████████▉ | 281/313 [00:09<00:01, 28.87it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  90%|█████████ | 282/313 [00:09<00:01, 28.90it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  90%|█████████ | 283/313 [00:09<00:01, 28.94it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  91%|█████████ | 284/313 [00:09<00:01, 28.98it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  91%|█████████ | 285/313 [00:09<00:00, 29.02it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  91%|█████████▏| 286/313 [00:09<00:00, 29.06it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  92%|█████████▏| 287/313 [00:09<00:00, 29.09it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  92%|█████████▏| 288/313 [00:09<00:00, 29.13it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  92%|█████████▏| 289/313 [00:09<00:00, 29.16it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  93%|█████████▎| 290/313 [00:09<00:00, 29.20it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  93%|█████████▎| 291/313 [00:09<00:00, 29.24it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  93%|█████████▎| 292/313 [00:09<00:00, 29.28it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  94%|█████████▎| 293/313 [00:09<00:00, 29.31it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  94%|█████████▍| 294/313 [00:10<00:00, 29.35it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  94%|█████████▍| 295/313 [00:10<00:00, 29.38it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  95%|█████████▍| 296/313 [00:10<00:00, 29.42it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  95%|█████████▍| 297/313 [00:10<00:00, 29.45it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  95%|█████████▌| 298/313 [00:10<00:00, 29.49it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  96%|█████████▌| 299/313 [00:10<00:00, 29.53it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  96%|█████████▌| 300/313 [00:10<00:00, 29.56it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  96%|█████████▌| 301/313 [00:10<00:00, 29.59it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  96%|█████████▋| 302/313 [00:10<00:00, 29.63it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  97%|█████████▋| 303/313 [00:10<00:00, 29.67it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  97%|█████████▋| 304/313 [00:10<00:00, 29.70it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  97%|█████████▋| 305/313 [00:10<00:00, 29.73it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  98%|█████████▊| 306/313 [00:10<00:00, 29.77it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  98%|█████████▊| 307/313 [00:10<00:00, 29.80it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  98%|█████████▊| 308/313 [00:10<00:00, 29.83it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  99%|█████████▊| 309/313 [00:10<00:00, 29.87it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  99%|█████████▉| 310/313 [00:10<00:00, 29.90it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1:  99%|█████████▉| 311/313 [00:10<00:00, 29.94it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1: 100%|█████████▉| 312/313 [00:10<00:00, 29.97it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 1: 100%|██████████| 313/313 [00:10<00:00, 30.02it/s, loss=2.23, v_num=1.21e+7]\n",
      "Epoch 2:  80%|███████▉  | 250/313 [00:08<00:02, 28.05it/s, loss=1.99, v_num=1.21e+7]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  80%|████████  | 251/313 [00:08<00:02, 28.06it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  81%|████████  | 252/313 [00:08<00:02, 28.10it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  81%|████████  | 253/313 [00:08<00:02, 28.14it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  81%|████████  | 254/313 [00:09<00:02, 28.18it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  81%|████████▏ | 255/313 [00:09<00:02, 28.22it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  82%|████████▏ | 256/313 [00:09<00:02, 28.26it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  82%|████████▏ | 257/313 [00:09<00:01, 28.30it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  82%|████████▏ | 258/313 [00:09<00:01, 28.34it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  83%|████████▎ | 259/313 [00:09<00:01, 28.38it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  83%|████████▎ | 260/313 [00:09<00:01, 28.42it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  83%|████████▎ | 261/313 [00:09<00:01, 28.46it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  84%|████████▎ | 262/313 [00:09<00:01, 28.50it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  84%|████████▍ | 263/313 [00:09<00:01, 28.53it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  84%|████████▍ | 264/313 [00:09<00:01, 28.57it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  85%|████████▍ | 265/313 [00:09<00:01, 28.61it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  85%|████████▍ | 266/313 [00:09<00:01, 28.65it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  85%|████████▌ | 267/313 [00:09<00:01, 28.69it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  86%|████████▌ | 268/313 [00:09<00:01, 28.73it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  86%|████████▌ | 269/313 [00:09<00:01, 28.76it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  86%|████████▋ | 270/313 [00:09<00:01, 28.80it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  87%|████████▋ | 271/313 [00:09<00:01, 28.84it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  87%|████████▋ | 272/313 [00:09<00:01, 28.87it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  87%|████████▋ | 273/313 [00:09<00:01, 28.91it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  88%|████████▊ | 274/313 [00:09<00:01, 28.95it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  88%|████████▊ | 275/313 [00:09<00:01, 28.99it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  88%|████████▊ | 276/313 [00:09<00:01, 29.03it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  88%|████████▊ | 277/313 [00:09<00:01, 29.07it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  89%|████████▉ | 278/313 [00:09<00:01, 29.11it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  89%|████████▉ | 279/313 [00:09<00:01, 29.15it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  89%|████████▉ | 280/313 [00:09<00:01, 29.19it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  90%|████████▉ | 281/313 [00:09<00:01, 29.23it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  90%|█████████ | 282/313 [00:09<00:01, 29.26it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  90%|█████████ | 283/313 [00:09<00:01, 29.30it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  91%|█████████ | 284/313 [00:09<00:00, 29.34it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  91%|█████████ | 285/313 [00:09<00:00, 29.38it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  91%|█████████▏| 286/313 [00:09<00:00, 29.42it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  92%|█████████▏| 287/313 [00:09<00:00, 29.45it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  92%|█████████▏| 288/313 [00:09<00:00, 29.49it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  92%|█████████▏| 289/313 [00:09<00:00, 29.52it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  93%|█████████▎| 290/313 [00:09<00:00, 29.56it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  93%|█████████▎| 291/313 [00:09<00:00, 29.60it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  93%|█████████▎| 292/313 [00:09<00:00, 29.63it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  94%|█████████▎| 293/313 [00:09<00:00, 29.67it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  94%|█████████▍| 294/313 [00:09<00:00, 29.71it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  94%|█████████▍| 295/313 [00:09<00:00, 29.74it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  95%|█████████▍| 296/313 [00:09<00:00, 29.77it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  95%|█████████▍| 297/313 [00:09<00:00, 29.81it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  95%|█████████▌| 298/313 [00:09<00:00, 29.85it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  96%|█████████▌| 299/313 [00:10<00:00, 29.88it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  96%|█████████▌| 300/313 [00:10<00:00, 29.92it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  96%|█████████▌| 301/313 [00:10<00:00, 29.95it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  96%|█████████▋| 302/313 [00:10<00:00, 29.98it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  97%|█████████▋| 303/313 [00:10<00:00, 30.02it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  97%|█████████▋| 304/313 [00:10<00:00, 30.05it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  97%|█████████▋| 305/313 [00:10<00:00, 30.09it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  98%|█████████▊| 306/313 [00:10<00:00, 30.12it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  98%|█████████▊| 307/313 [00:10<00:00, 30.15it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  98%|█████████▊| 308/313 [00:10<00:00, 30.19it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  99%|█████████▊| 309/313 [00:10<00:00, 30.22it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  99%|█████████▉| 310/313 [00:10<00:00, 30.25it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2:  99%|█████████▉| 311/313 [00:10<00:00, 30.29it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2: 100%|█████████▉| 312/313 [00:10<00:00, 30.32it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 2: 100%|██████████| 313/313 [00:10<00:00, 30.37it/s, loss=1.99, v_num=1.21e+7]\n",
      "Epoch 3:  80%|███████▉  | 250/313 [00:08<00:02, 28.14it/s, loss=1.69, v_num=1.21e+7]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 251/313 [00:08<00:02, 28.17it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  81%|████████  | 252/313 [00:08<00:02, 28.21it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  81%|████████  | 253/313 [00:08<00:02, 28.25it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  81%|████████  | 254/313 [00:08<00:02, 28.30it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  81%|████████▏ | 255/313 [00:08<00:02, 28.34it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  82%|████████▏ | 256/313 [00:09<00:02, 28.38it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  82%|████████▏ | 257/313 [00:09<00:01, 28.43it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  82%|████████▏ | 258/313 [00:09<00:01, 28.47it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  83%|████████▎ | 259/313 [00:09<00:01, 28.52it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  83%|████████▎ | 260/313 [00:09<00:01, 28.56it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  83%|████████▎ | 261/313 [00:09<00:01, 28.60it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  84%|████████▎ | 262/313 [00:09<00:01, 28.64it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  84%|████████▍ | 263/313 [00:09<00:01, 28.68it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  84%|████████▍ | 264/313 [00:09<00:01, 28.72it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  85%|████████▍ | 265/313 [00:09<00:01, 28.76it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  85%|████████▍ | 266/313 [00:09<00:01, 28.80it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  85%|████████▌ | 267/313 [00:09<00:01, 28.85it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  86%|████████▌ | 268/313 [00:09<00:01, 28.89it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  86%|████████▌ | 269/313 [00:09<00:01, 28.93it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  86%|████████▋ | 270/313 [00:09<00:01, 28.96it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  87%|████████▋ | 271/313 [00:09<00:01, 29.00it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  87%|████████▋ | 272/313 [00:09<00:01, 29.04it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  87%|████████▋ | 273/313 [00:09<00:01, 29.07it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  88%|████████▊ | 274/313 [00:09<00:01, 29.12it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  88%|████████▊ | 275/313 [00:09<00:01, 29.16it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  88%|████████▊ | 276/313 [00:09<00:01, 29.20it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  88%|████████▊ | 277/313 [00:09<00:01, 29.24it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  89%|████████▉ | 278/313 [00:09<00:01, 29.27it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  89%|████████▉ | 279/313 [00:09<00:01, 29.31it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  89%|████████▉ | 280/313 [00:09<00:01, 29.35it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  90%|████████▉ | 281/313 [00:09<00:01, 29.39it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  90%|█████████ | 282/313 [00:09<00:01, 29.43it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  90%|█████████ | 283/313 [00:09<00:01, 29.47it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  91%|█████████ | 284/313 [00:09<00:00, 29.51it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  91%|█████████ | 285/313 [00:09<00:00, 29.54it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  91%|█████████▏| 286/313 [00:09<00:00, 29.58it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  92%|█████████▏| 287/313 [00:09<00:00, 29.61it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  92%|█████████▏| 288/313 [00:09<00:00, 29.65it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  92%|█████████▏| 289/313 [00:09<00:00, 29.69it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  93%|█████████▎| 290/313 [00:09<00:00, 29.72it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  93%|█████████▎| 291/313 [00:09<00:00, 29.76it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  93%|█████████▎| 292/313 [00:09<00:00, 29.80it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  94%|█████████▎| 293/313 [00:09<00:00, 29.83it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  94%|█████████▍| 294/313 [00:09<00:00, 29.87it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  94%|█████████▍| 295/313 [00:09<00:00, 29.91it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  95%|█████████▍| 296/313 [00:09<00:00, 29.94it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  95%|█████████▍| 297/313 [00:09<00:00, 29.97it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  95%|█████████▌| 298/313 [00:09<00:00, 30.01it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  96%|█████████▌| 299/313 [00:09<00:00, 30.04it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  96%|█████████▌| 300/313 [00:09<00:00, 30.08it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  96%|█████████▌| 301/313 [00:09<00:00, 30.11it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  96%|█████████▋| 302/313 [00:10<00:00, 30.15it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  97%|█████████▋| 303/313 [00:10<00:00, 30.18it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  97%|█████████▋| 304/313 [00:10<00:00, 30.21it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  97%|█████████▋| 305/313 [00:10<00:00, 30.25it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  98%|█████████▊| 306/313 [00:10<00:00, 30.28it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  98%|█████████▊| 307/313 [00:10<00:00, 30.32it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  98%|█████████▊| 308/313 [00:10<00:00, 30.35it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  99%|█████████▊| 309/313 [00:10<00:00, 30.38it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  99%|█████████▉| 310/313 [00:10<00:00, 30.41it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3:  99%|█████████▉| 311/313 [00:10<00:00, 30.45it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3: 100%|█████████▉| 312/313 [00:10<00:00, 30.48it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 3: 100%|██████████| 313/313 [00:10<00:00, 30.53it/s, loss=1.69, v_num=1.21e+7]\n",
      "Epoch 4:  80%|███████▉  | 250/313 [00:08<00:02, 28.07it/s, loss=1.16, v_num=1.21e+7]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  80%|████████  | 251/313 [00:08<00:02, 28.10it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  81%|████████  | 252/313 [00:08<00:02, 28.14it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  81%|████████  | 253/313 [00:08<00:02, 28.18it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  81%|████████  | 254/313 [00:08<00:02, 28.22it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  81%|████████▏ | 255/313 [00:09<00:02, 28.27it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  82%|████████▏ | 256/313 [00:09<00:02, 28.31it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  82%|████████▏ | 257/313 [00:09<00:01, 28.36it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  82%|████████▏ | 258/313 [00:09<00:01, 28.40it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  83%|████████▎ | 259/313 [00:09<00:01, 28.44it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  83%|████████▎ | 260/313 [00:09<00:01, 28.48it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  83%|████████▎ | 261/313 [00:09<00:01, 28.52it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  84%|████████▎ | 262/313 [00:09<00:01, 28.56it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  84%|████████▍ | 263/313 [00:09<00:01, 28.60it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  84%|████████▍ | 264/313 [00:09<00:01, 28.64it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  85%|████████▍ | 265/313 [00:09<00:01, 28.68it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  85%|████████▍ | 266/313 [00:09<00:01, 28.72it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  85%|████████▌ | 267/313 [00:09<00:01, 28.77it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  86%|████████▌ | 268/313 [00:09<00:01, 28.80it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  86%|████████▌ | 269/313 [00:09<00:01, 28.84it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  86%|████████▋ | 270/313 [00:09<00:01, 28.88it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  87%|████████▋ | 271/313 [00:09<00:01, 28.92it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  87%|████████▋ | 272/313 [00:09<00:01, 28.95it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  87%|████████▋ | 273/313 [00:09<00:01, 28.99it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  88%|████████▊ | 274/313 [00:09<00:01, 29.03it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  88%|████████▊ | 275/313 [00:09<00:01, 29.07it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  88%|████████▊ | 276/313 [00:09<00:01, 29.11it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  88%|████████▊ | 277/313 [00:09<00:01, 29.15it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  89%|████████▉ | 278/313 [00:09<00:01, 29.19it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  89%|████████▉ | 279/313 [00:09<00:01, 29.23it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  89%|████████▉ | 280/313 [00:09<00:01, 29.27it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  90%|████████▉ | 281/313 [00:09<00:01, 29.30it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  90%|█████████ | 282/313 [00:09<00:01, 29.34it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  90%|█████████ | 283/313 [00:09<00:01, 29.38it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  91%|█████████ | 284/313 [00:09<00:00, 29.42it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  91%|█████████ | 285/313 [00:09<00:00, 29.45it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  91%|█████████▏| 286/313 [00:09<00:00, 29.49it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  92%|█████████▏| 287/313 [00:09<00:00, 29.52it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  92%|█████████▏| 288/313 [00:09<00:00, 29.56it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  92%|█████████▏| 289/313 [00:09<00:00, 29.60it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  93%|█████████▎| 290/313 [00:09<00:00, 29.63it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  93%|█████████▎| 291/313 [00:09<00:00, 29.67it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  93%|█████████▎| 292/313 [00:09<00:00, 29.71it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  94%|█████████▎| 293/313 [00:09<00:00, 29.74it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  94%|█████████▍| 294/313 [00:09<00:00, 29.78it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  94%|█████████▍| 295/313 [00:09<00:00, 29.81it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  95%|█████████▍| 296/313 [00:09<00:00, 29.84it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  95%|█████████▍| 297/313 [00:09<00:00, 29.88it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  95%|█████████▌| 298/313 [00:09<00:00, 29.91it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  96%|█████████▌| 299/313 [00:09<00:00, 29.95it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  96%|█████████▌| 300/313 [00:10<00:00, 29.98it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  96%|█████████▌| 301/313 [00:10<00:00, 30.01it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  96%|█████████▋| 302/313 [00:10<00:00, 30.05it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  97%|█████████▋| 303/313 [00:10<00:00, 30.08it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  97%|█████████▋| 304/313 [00:10<00:00, 30.12it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  97%|█████████▋| 305/313 [00:10<00:00, 30.15it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  98%|█████████▊| 306/313 [00:10<00:00, 30.19it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  98%|█████████▊| 307/313 [00:10<00:00, 30.22it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  98%|█████████▊| 308/313 [00:10<00:00, 30.25it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  99%|█████████▊| 309/313 [00:10<00:00, 30.28it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  99%|█████████▉| 310/313 [00:10<00:00, 30.31it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4:  99%|█████████▉| 311/313 [00:10<00:00, 30.35it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4: 100%|█████████▉| 312/313 [00:10<00:00, 30.38it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 4: 100%|██████████| 313/313 [00:10<00:00, 30.43it/s, loss=1.16, v_num=1.21e+7]\n",
      "Epoch 5:  80%|███████▉  | 250/313 [00:09<00:02, 27.65it/s, loss=2.2, v_num=1.21e+7] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  80%|████████  | 251/313 [00:09<00:02, 27.68it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  81%|████████  | 252/313 [00:09<00:02, 27.72it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  81%|████████  | 253/313 [00:09<00:02, 27.76it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  81%|████████  | 254/313 [00:09<00:02, 27.81it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  81%|████████▏ | 255/313 [00:09<00:02, 27.85it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  82%|████████▏ | 256/313 [00:09<00:02, 27.90it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  82%|████████▏ | 257/313 [00:09<00:02, 27.94it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  82%|████████▏ | 258/313 [00:09<00:01, 27.98it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  83%|████████▎ | 259/313 [00:09<00:01, 28.03it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  83%|████████▎ | 260/313 [00:09<00:01, 28.07it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  83%|████████▎ | 261/313 [00:09<00:01, 28.11it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  84%|████████▎ | 262/313 [00:09<00:01, 28.15it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  84%|████████▍ | 263/313 [00:09<00:01, 28.19it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  84%|████████▍ | 264/313 [00:09<00:01, 28.23it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  85%|████████▍ | 265/313 [00:09<00:01, 28.27it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  85%|████████▍ | 266/313 [00:09<00:01, 28.31it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  85%|████████▌ | 267/313 [00:09<00:01, 28.36it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  86%|████████▌ | 268/313 [00:09<00:01, 28.40it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  86%|████████▌ | 269/313 [00:09<00:01, 28.44it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  86%|████████▋ | 270/313 [00:09<00:01, 28.48it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  87%|████████▋ | 271/313 [00:09<00:01, 28.52it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  87%|████████▋ | 272/313 [00:09<00:01, 28.55it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  87%|████████▋ | 273/313 [00:09<00:01, 28.59it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  88%|████████▊ | 274/313 [00:09<00:01, 28.63it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  88%|████████▊ | 275/313 [00:09<00:01, 28.67it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  88%|████████▊ | 276/313 [00:09<00:01, 28.71it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  88%|████████▊ | 277/313 [00:09<00:01, 28.75it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  89%|████████▉ | 278/313 [00:09<00:01, 28.79it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  89%|████████▉ | 279/313 [00:09<00:01, 28.83it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  89%|████████▉ | 280/313 [00:09<00:01, 28.87it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  90%|████████▉ | 281/313 [00:09<00:01, 28.90it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  90%|█████████ | 282/313 [00:09<00:01, 28.94it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  90%|█████████ | 283/313 [00:09<00:01, 28.98it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  91%|█████████ | 284/313 [00:09<00:00, 29.02it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  91%|█████████ | 285/313 [00:09<00:00, 29.06it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  91%|█████████▏| 286/313 [00:09<00:00, 29.09it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  92%|█████████▏| 287/313 [00:09<00:00, 29.13it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  92%|█████████▏| 288/313 [00:09<00:00, 29.16it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  92%|█████████▏| 289/313 [00:09<00:00, 29.20it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  93%|█████████▎| 290/313 [00:09<00:00, 29.24it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  93%|█████████▎| 291/313 [00:09<00:00, 29.28it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  93%|█████████▎| 292/313 [00:09<00:00, 29.31it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  94%|█████████▎| 293/313 [00:09<00:00, 29.35it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  94%|█████████▍| 294/313 [00:10<00:00, 29.39it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  94%|█████████▍| 295/313 [00:10<00:00, 29.42it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  95%|█████████▍| 296/313 [00:10<00:00, 29.45it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  95%|█████████▍| 297/313 [00:10<00:00, 29.49it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  95%|█████████▌| 298/313 [00:10<00:00, 29.53it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  96%|█████████▌| 299/313 [00:10<00:00, 29.56it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  96%|█████████▌| 300/313 [00:10<00:00, 29.60it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  96%|█████████▌| 301/313 [00:10<00:00, 29.63it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  96%|█████████▋| 302/313 [00:10<00:00, 29.67it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  97%|█████████▋| 303/313 [00:10<00:00, 29.70it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  97%|█████████▋| 304/313 [00:10<00:00, 29.74it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  97%|█████████▋| 305/313 [00:10<00:00, 29.77it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  98%|█████████▊| 306/313 [00:10<00:00, 29.81it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  98%|█████████▊| 307/313 [00:10<00:00, 29.84it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  98%|█████████▊| 308/313 [00:10<00:00, 29.87it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  99%|█████████▊| 309/313 [00:10<00:00, 29.90it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  99%|█████████▉| 310/313 [00:10<00:00, 29.93it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5:  99%|█████████▉| 311/313 [00:10<00:00, 29.97it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5: 100%|█████████▉| 312/313 [00:10<00:00, 30.00it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 5: 100%|██████████| 313/313 [00:10<00:00, 30.05it/s, loss=2.2, v_num=1.21e+7]\n",
      "Epoch 6:  80%|███████▉  | 250/313 [00:08<00:02, 28.17it/s, loss=1.66, v_num=1.21e+7] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  80%|████████  | 251/313 [00:08<00:02, 28.19it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  81%|████████  | 252/313 [00:08<00:02, 28.23it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  81%|████████  | 253/313 [00:08<00:02, 28.27it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  81%|████████  | 254/313 [00:08<00:02, 28.32it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  81%|████████▏ | 255/313 [00:08<00:02, 28.36it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  82%|████████▏ | 256/313 [00:09<00:02, 28.41it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  82%|████████▏ | 257/313 [00:09<00:01, 28.45it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  82%|████████▏ | 258/313 [00:09<00:01, 28.49it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  83%|████████▎ | 259/313 [00:09<00:01, 28.54it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  83%|████████▎ | 260/313 [00:09<00:01, 28.57it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  83%|████████▎ | 261/313 [00:09<00:01, 28.61it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  84%|████████▎ | 262/313 [00:09<00:01, 28.66it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  84%|████████▍ | 263/313 [00:09<00:01, 28.70it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  84%|████████▍ | 264/313 [00:09<00:01, 28.74it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  85%|████████▍ | 265/313 [00:09<00:01, 28.78it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  85%|████████▍ | 266/313 [00:09<00:01, 28.82it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  85%|████████▌ | 267/313 [00:09<00:01, 28.86it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  86%|████████▌ | 268/313 [00:09<00:01, 28.90it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  86%|████████▌ | 269/313 [00:09<00:01, 28.94it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  86%|████████▋ | 270/313 [00:09<00:01, 28.98it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  87%|████████▋ | 271/313 [00:09<00:01, 29.02it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  87%|████████▋ | 272/313 [00:09<00:01, 29.05it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  87%|████████▋ | 273/313 [00:09<00:01, 29.09it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  88%|████████▊ | 274/313 [00:09<00:01, 29.13it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  88%|████████▊ | 275/313 [00:09<00:01, 29.17it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  88%|████████▊ | 276/313 [00:09<00:01, 29.21it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  88%|████████▊ | 277/313 [00:09<00:01, 29.25it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  89%|████████▉ | 278/313 [00:09<00:01, 29.29it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  89%|████████▉ | 279/313 [00:09<00:01, 29.33it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  89%|████████▉ | 280/313 [00:09<00:01, 29.37it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  90%|████████▉ | 281/313 [00:09<00:01, 29.40it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  90%|█████████ | 282/313 [00:09<00:01, 29.44it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  90%|█████████ | 283/313 [00:09<00:01, 29.48it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  91%|█████████ | 284/313 [00:09<00:00, 29.52it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  91%|█████████ | 285/313 [00:09<00:00, 29.55it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  91%|█████████▏| 286/313 [00:09<00:00, 29.59it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  92%|█████████▏| 287/313 [00:09<00:00, 29.62it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  92%|█████████▏| 288/313 [00:09<00:00, 29.66it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  92%|█████████▏| 289/313 [00:09<00:00, 29.70it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  93%|█████████▎| 290/313 [00:09<00:00, 29.73it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  93%|█████████▎| 291/313 [00:09<00:00, 29.77it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  93%|█████████▎| 292/313 [00:09<00:00, 29.81it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  94%|█████████▎| 293/313 [00:09<00:00, 29.84it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  94%|█████████▍| 294/313 [00:09<00:00, 29.88it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  94%|█████████▍| 295/313 [00:09<00:00, 29.91it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  95%|█████████▍| 296/313 [00:09<00:00, 29.94it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  95%|█████████▍| 297/313 [00:09<00:00, 29.98it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  95%|█████████▌| 298/313 [00:09<00:00, 30.02it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  96%|█████████▌| 299/313 [00:09<00:00, 30.05it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  96%|█████████▌| 300/313 [00:09<00:00, 30.09it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  96%|█████████▌| 301/313 [00:09<00:00, 30.12it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  96%|█████████▋| 302/313 [00:10<00:00, 30.15it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  97%|█████████▋| 303/313 [00:10<00:00, 30.19it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  97%|█████████▋| 304/313 [00:10<00:00, 30.22it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  97%|█████████▋| 305/313 [00:10<00:00, 30.25it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  98%|█████████▊| 306/313 [00:10<00:00, 30.29it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  98%|█████████▊| 307/313 [00:10<00:00, 30.32it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  98%|█████████▊| 308/313 [00:10<00:00, 30.35it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  99%|█████████▊| 309/313 [00:10<00:00, 30.38it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  99%|█████████▉| 310/313 [00:10<00:00, 30.42it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6:  99%|█████████▉| 311/313 [00:10<00:00, 30.45it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6: 100%|█████████▉| 312/313 [00:10<00:00, 30.48it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 6: 100%|██████████| 313/313 [00:10<00:00, 30.53it/s, loss=1.66, v_num=1.21e+7]\n",
      "Epoch 7:  80%|███████▉  | 250/313 [00:08<00:02, 28.00it/s, loss=2.03, v_num=1.21e+7]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  80%|████████  | 251/313 [00:08<00:02, 28.01it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  81%|████████  | 252/313 [00:08<00:02, 28.04it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  81%|████████  | 253/313 [00:09<00:02, 28.08it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  81%|████████  | 254/313 [00:09<00:02, 28.12it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  81%|████████▏ | 255/313 [00:09<00:02, 28.16it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  82%|████████▏ | 256/313 [00:09<00:02, 28.20it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  82%|████████▏ | 257/313 [00:09<00:01, 28.24it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  82%|████████▏ | 258/313 [00:09<00:01, 28.27it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  83%|████████▎ | 259/313 [00:09<00:01, 28.31it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  83%|████████▎ | 260/313 [00:09<00:01, 28.35it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  83%|████████▎ | 261/313 [00:09<00:01, 28.38it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  84%|████████▎ | 262/313 [00:09<00:01, 28.42it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  84%|████████▍ | 263/313 [00:09<00:01, 28.45it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  84%|████████▍ | 264/313 [00:09<00:01, 28.49it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  85%|████████▍ | 265/313 [00:09<00:01, 28.52it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  85%|████████▍ | 266/313 [00:09<00:01, 28.56it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  85%|████████▌ | 267/313 [00:09<00:01, 28.60it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  86%|████████▌ | 268/313 [00:09<00:01, 28.63it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  86%|████████▌ | 269/313 [00:09<00:01, 28.67it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  86%|████████▋ | 270/313 [00:09<00:01, 28.70it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  87%|████████▋ | 271/313 [00:09<00:01, 28.73it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  87%|████████▋ | 272/313 [00:09<00:01, 28.77it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  87%|████████▋ | 273/313 [00:09<00:01, 28.80it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  88%|████████▊ | 274/313 [00:09<00:01, 28.83it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  88%|████████▊ | 275/313 [00:09<00:01, 28.87it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  88%|████████▊ | 276/313 [00:09<00:01, 28.90it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  88%|████████▊ | 277/313 [00:09<00:01, 28.94it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  89%|████████▉ | 278/313 [00:09<00:01, 28.97it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  89%|████████▉ | 279/313 [00:09<00:01, 29.00it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  89%|████████▉ | 280/313 [00:09<00:01, 29.04it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  90%|████████▉ | 281/313 [00:09<00:01, 29.07it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  90%|█████████ | 282/313 [00:09<00:01, 29.10it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  90%|█████████ | 283/313 [00:09<00:01, 29.14it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  91%|█████████ | 284/313 [00:09<00:00, 29.17it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  91%|█████████ | 285/313 [00:09<00:00, 29.20it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  91%|█████████▏| 286/313 [00:09<00:00, 29.24it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  92%|█████████▏| 287/313 [00:09<00:00, 29.26it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  92%|█████████▏| 288/313 [00:09<00:00, 29.29it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  92%|█████████▏| 289/313 [00:09<00:00, 29.33it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  93%|█████████▎| 290/313 [00:09<00:00, 29.36it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  93%|█████████▎| 291/313 [00:09<00:00, 29.39it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  93%|█████████▎| 292/313 [00:09<00:00, 29.42it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  94%|█████████▎| 293/313 [00:09<00:00, 29.45it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  94%|█████████▍| 294/313 [00:09<00:00, 29.48it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  94%|█████████▍| 295/313 [00:09<00:00, 29.52it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  95%|█████████▍| 296/313 [00:10<00:00, 29.54it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  95%|█████████▍| 297/313 [00:10<00:00, 29.57it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  95%|█████████▌| 298/313 [00:10<00:00, 29.61it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  96%|█████████▌| 299/313 [00:10<00:00, 29.64it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  96%|█████████▌| 300/313 [00:10<00:00, 29.66it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  96%|█████████▌| 301/313 [00:10<00:00, 29.69it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  96%|█████████▋| 302/313 [00:10<00:00, 29.72it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  97%|█████████▋| 303/313 [00:10<00:00, 29.75it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  97%|█████████▋| 304/313 [00:10<00:00, 29.78it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  97%|█████████▋| 305/313 [00:10<00:00, 29.81it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  98%|█████████▊| 306/313 [00:10<00:00, 29.84it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  98%|█████████▊| 307/313 [00:10<00:00, 29.87it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  98%|█████████▊| 308/313 [00:10<00:00, 29.90it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  99%|█████████▊| 309/313 [00:10<00:00, 29.93it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  99%|█████████▉| 310/313 [00:10<00:00, 29.96it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7:  99%|█████████▉| 311/313 [00:10<00:00, 29.99it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7: 100%|█████████▉| 312/313 [00:10<00:00, 30.01it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 7: 100%|██████████| 313/313 [00:10<00:00, 30.06it/s, loss=2.03, v_num=1.21e+7]\n",
      "Epoch 8:  80%|███████▉  | 250/313 [00:09<00:02, 27.56it/s, loss=1.96, v_num=1.21e+7]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  80%|████████  | 251/313 [00:09<00:02, 27.57it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  81%|████████  | 252/313 [00:09<00:02, 27.61it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  81%|████████  | 253/313 [00:09<00:02, 27.65it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  81%|████████  | 254/313 [00:09<00:02, 27.68it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  81%|████████▏ | 255/313 [00:09<00:02, 27.72it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  82%|████████▏ | 256/313 [00:09<00:02, 27.76it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  82%|████████▏ | 257/313 [00:09<00:02, 27.80it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  82%|████████▏ | 258/313 [00:09<00:01, 27.84it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  83%|████████▎ | 259/313 [00:09<00:01, 27.88it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  83%|████████▎ | 260/313 [00:09<00:01, 27.91it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  83%|████████▎ | 261/313 [00:09<00:01, 27.94it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  84%|████████▎ | 262/313 [00:09<00:01, 27.98it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  84%|████████▍ | 263/313 [00:09<00:01, 28.02it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  84%|████████▍ | 264/313 [00:09<00:01, 28.05it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  85%|████████▍ | 265/313 [00:09<00:01, 28.09it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  85%|████████▍ | 266/313 [00:09<00:01, 28.13it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  85%|████████▌ | 267/313 [00:09<00:01, 28.17it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  86%|████████▌ | 268/313 [00:09<00:01, 28.20it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  86%|████████▌ | 269/313 [00:09<00:01, 28.24it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  86%|████████▋ | 270/313 [00:09<00:01, 28.28it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  87%|████████▋ | 271/313 [00:09<00:01, 28.32it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  87%|████████▋ | 272/313 [00:09<00:01, 28.35it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  87%|████████▋ | 273/313 [00:09<00:01, 28.39it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  88%|████████▊ | 274/313 [00:09<00:01, 28.43it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  88%|████████▊ | 275/313 [00:09<00:01, 28.47it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  88%|████████▊ | 276/313 [00:09<00:01, 28.51it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  88%|████████▊ | 277/313 [00:09<00:01, 28.55it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  89%|████████▉ | 278/313 [00:09<00:01, 28.59it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  89%|████████▉ | 279/313 [00:09<00:01, 28.63it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  89%|████████▉ | 280/313 [00:09<00:01, 28.67it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  90%|████████▉ | 281/313 [00:09<00:01, 28.71it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  90%|█████████ | 282/313 [00:09<00:01, 28.74it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  90%|█████████ | 283/313 [00:09<00:01, 28.78it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  91%|█████████ | 284/313 [00:09<00:01, 28.82it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  91%|█████████ | 285/313 [00:09<00:00, 28.86it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  91%|█████████▏| 286/313 [00:09<00:00, 28.90it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  92%|█████████▏| 287/313 [00:09<00:00, 28.93it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  92%|█████████▏| 288/313 [00:09<00:00, 28.97it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  92%|█████████▏| 289/313 [00:09<00:00, 29.01it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  93%|█████████▎| 290/313 [00:09<00:00, 29.05it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  93%|█████████▎| 291/313 [00:10<00:00, 29.08it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  93%|█████████▎| 292/313 [00:10<00:00, 29.12it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  94%|█████████▎| 293/313 [00:10<00:00, 29.16it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  94%|█████████▍| 294/313 [00:10<00:00, 29.19it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  94%|█████████▍| 295/313 [00:10<00:00, 29.23it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  95%|█████████▍| 296/313 [00:10<00:00, 29.26it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  95%|█████████▍| 297/313 [00:10<00:00, 29.30it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  95%|█████████▌| 298/313 [00:10<00:00, 29.33it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  96%|█████████▌| 299/313 [00:10<00:00, 29.37it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  96%|█████████▌| 300/313 [00:10<00:00, 29.41it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  96%|█████████▌| 301/313 [00:10<00:00, 29.44it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  96%|█████████▋| 302/313 [00:10<00:00, 29.47it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  97%|█████████▋| 303/313 [00:10<00:00, 29.51it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  97%|█████████▋| 304/313 [00:10<00:00, 29.54it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  97%|█████████▋| 305/313 [00:10<00:00, 29.58it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  98%|█████████▊| 306/313 [00:10<00:00, 29.61it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  98%|█████████▊| 307/313 [00:10<00:00, 29.64it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  98%|█████████▊| 308/313 [00:10<00:00, 29.68it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  99%|█████████▊| 309/313 [00:10<00:00, 29.71it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  99%|█████████▉| 310/313 [00:10<00:00, 29.74it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8:  99%|█████████▉| 311/313 [00:10<00:00, 29.78it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8: 100%|█████████▉| 312/313 [00:10<00:00, 29.81it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 8: 100%|██████████| 313/313 [00:10<00:00, 29.86it/s, loss=1.96, v_num=1.21e+7]\n",
      "Epoch 9:  80%|███████▉  | 250/313 [00:09<00:02, 27.75it/s, loss=1.37, v_num=1.21e+7]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  80%|████████  | 251/313 [00:09<00:02, 27.77it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  81%|████████  | 252/313 [00:09<00:02, 27.82it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  81%|████████  | 253/313 [00:09<00:02, 27.86it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  81%|████████  | 254/313 [00:09<00:02, 27.90it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  81%|████████▏ | 255/313 [00:09<00:02, 27.94it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  82%|████████▏ | 256/313 [00:09<00:02, 27.99it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  82%|████████▏ | 257/313 [00:09<00:01, 28.04it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  82%|████████▏ | 258/313 [00:09<00:01, 28.08it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  83%|████████▎ | 259/313 [00:09<00:01, 28.12it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  83%|████████▎ | 260/313 [00:09<00:01, 28.16it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  83%|████████▎ | 261/313 [00:09<00:01, 28.20it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  84%|████████▎ | 262/313 [00:09<00:01, 28.24it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  84%|████████▍ | 263/313 [00:09<00:01, 28.28it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  84%|████████▍ | 264/313 [00:09<00:01, 28.32it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  85%|████████▍ | 265/313 [00:09<00:01, 28.37it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  85%|████████▍ | 266/313 [00:09<00:01, 28.41it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  85%|████████▌ | 267/313 [00:09<00:01, 28.45it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  86%|████████▌ | 268/313 [00:09<00:01, 28.49it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  86%|████████▌ | 269/313 [00:09<00:01, 28.53it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  86%|████████▋ | 270/313 [00:09<00:01, 28.57it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  87%|████████▋ | 271/313 [00:09<00:01, 28.61it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  87%|████████▋ | 272/313 [00:09<00:01, 28.65it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  87%|████████▋ | 273/313 [00:09<00:01, 28.68it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  88%|████████▊ | 274/313 [00:09<00:01, 28.72it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  88%|████████▊ | 275/313 [00:09<00:01, 28.76it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  88%|████████▊ | 276/313 [00:09<00:01, 28.80it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  88%|████████▊ | 277/313 [00:09<00:01, 28.84it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  89%|████████▉ | 278/313 [00:09<00:01, 28.88it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  89%|████████▉ | 279/313 [00:09<00:01, 28.92it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  89%|████████▉ | 280/313 [00:09<00:01, 28.96it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  90%|████████▉ | 281/313 [00:09<00:01, 29.00it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  90%|█████████ | 282/313 [00:09<00:01, 29.03it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  90%|█████████ | 283/313 [00:09<00:01, 29.07it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  91%|█████████ | 284/313 [00:09<00:00, 29.11it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  91%|█████████ | 285/313 [00:09<00:00, 29.15it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  91%|█████████▏| 286/313 [00:09<00:00, 29.19it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  92%|█████████▏| 287/313 [00:09<00:00, 29.22it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  92%|█████████▏| 288/313 [00:09<00:00, 29.26it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  92%|█████████▏| 289/313 [00:09<00:00, 29.30it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  93%|█████████▎| 290/313 [00:09<00:00, 29.34it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  93%|█████████▎| 291/313 [00:09<00:00, 29.37it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  93%|█████████▎| 292/313 [00:09<00:00, 29.41it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  94%|█████████▎| 293/313 [00:09<00:00, 29.44it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  94%|█████████▍| 294/313 [00:09<00:00, 29.48it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  94%|█████████▍| 295/313 [00:09<00:00, 29.51it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  95%|█████████▍| 296/313 [00:10<00:00, 29.55it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  95%|█████████▍| 297/313 [00:10<00:00, 29.58it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  95%|█████████▌| 298/313 [00:10<00:00, 29.62it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  96%|█████████▌| 299/313 [00:10<00:00, 29.66it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  96%|█████████▌| 300/313 [00:10<00:00, 29.69it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  96%|█████████▌| 301/313 [00:10<00:00, 29.72it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  96%|█████████▋| 302/313 [00:10<00:00, 29.76it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  97%|█████████▋| 303/313 [00:10<00:00, 29.79it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  97%|█████████▋| 304/313 [00:10<00:00, 29.83it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  97%|█████████▋| 305/313 [00:10<00:00, 29.86it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  98%|█████████▊| 306/313 [00:10<00:00, 29.89it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  98%|█████████▊| 307/313 [00:10<00:00, 29.93it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  98%|█████████▊| 308/313 [00:10<00:00, 29.96it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  99%|█████████▊| 309/313 [00:10<00:00, 29.99it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  99%|█████████▉| 310/313 [00:10<00:00, 30.03it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9:  99%|█████████▉| 311/313 [00:10<00:00, 30.06it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9: 100%|█████████▉| 312/313 [00:10<00:00, 30.09it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 9: 100%|██████████| 313/313 [00:10<00:00, 30.14it/s, loss=1.37, v_num=1.21e+7]\n",
      "Epoch 10:  80%|███████▉  | 250/313 [00:09<00:02, 27.39it/s, loss=1.3, v_num=1.21e+7] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  80%|████████  | 251/313 [00:09<00:02, 27.42it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  81%|████████  | 252/313 [00:09<00:02, 27.46it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  81%|████████  | 253/313 [00:09<00:02, 27.50it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  81%|████████  | 254/313 [00:09<00:02, 27.54it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  81%|████████▏ | 255/313 [00:09<00:02, 27.58it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  82%|████████▏ | 256/313 [00:09<00:02, 27.63it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  82%|████████▏ | 257/313 [00:09<00:02, 27.67it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  82%|████████▏ | 258/313 [00:09<00:01, 27.71it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  83%|████████▎ | 259/313 [00:09<00:01, 27.75it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  83%|████████▎ | 260/313 [00:09<00:01, 27.79it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  83%|████████▎ | 261/313 [00:09<00:01, 27.83it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  84%|████████▎ | 262/313 [00:09<00:01, 27.88it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  84%|████████▍ | 263/313 [00:09<00:01, 27.92it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  84%|████████▍ | 264/313 [00:09<00:01, 27.96it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  85%|████████▍ | 265/313 [00:09<00:01, 28.00it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  85%|████████▍ | 266/313 [00:09<00:01, 28.04it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  85%|████████▌ | 267/313 [00:09<00:01, 28.08it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  86%|████████▌ | 268/313 [00:09<00:01, 28.12it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  86%|████████▌ | 269/313 [00:09<00:01, 28.16it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  86%|████████▋ | 270/313 [00:09<00:01, 28.20it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  87%|████████▋ | 271/313 [00:09<00:01, 28.24it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  87%|████████▋ | 272/313 [00:09<00:01, 28.27it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  87%|████████▋ | 273/313 [00:09<00:01, 28.31it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  88%|████████▊ | 274/313 [00:09<00:01, 28.35it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  88%|████████▊ | 275/313 [00:09<00:01, 28.39it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  88%|████████▊ | 276/313 [00:09<00:01, 28.43it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  88%|████████▊ | 277/313 [00:09<00:01, 28.47it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  89%|████████▉ | 278/313 [00:09<00:01, 28.51it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  89%|████████▉ | 279/313 [00:09<00:01, 28.54it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  89%|████████▉ | 280/313 [00:09<00:01, 28.58it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  90%|████████▉ | 281/313 [00:09<00:01, 28.62it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  90%|█████████ | 282/313 [00:09<00:01, 28.65it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  90%|█████████ | 283/313 [00:09<00:01, 28.69it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  91%|█████████ | 284/313 [00:09<00:01, 28.73it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  91%|█████████ | 285/313 [00:09<00:00, 28.77it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  91%|█████████▏| 286/313 [00:09<00:00, 28.81it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  92%|█████████▏| 287/313 [00:09<00:00, 28.84it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  92%|█████████▏| 288/313 [00:09<00:00, 28.87it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  92%|█████████▏| 289/313 [00:09<00:00, 28.91it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  93%|█████████▎| 290/313 [00:10<00:00, 28.95it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  93%|█████████▎| 291/313 [00:10<00:00, 28.98it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  93%|█████████▎| 292/313 [00:10<00:00, 29.02it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  94%|█████████▎| 293/313 [00:10<00:00, 29.06it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  94%|█████████▍| 294/313 [00:10<00:00, 29.09it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  94%|█████████▍| 295/313 [00:10<00:00, 29.13it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  95%|█████████▍| 296/313 [00:10<00:00, 29.16it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  95%|█████████▍| 297/313 [00:10<00:00, 29.19it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  95%|█████████▌| 298/313 [00:10<00:00, 29.23it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  96%|█████████▌| 299/313 [00:10<00:00, 29.26it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  96%|█████████▌| 300/313 [00:10<00:00, 29.30it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  96%|█████████▌| 301/313 [00:10<00:00, 29.33it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  96%|█████████▋| 302/313 [00:10<00:00, 29.37it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  97%|█████████▋| 303/313 [00:10<00:00, 29.40it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  97%|█████████▋| 304/313 [00:10<00:00, 29.43it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  97%|█████████▋| 305/313 [00:10<00:00, 29.47it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  98%|█████████▊| 306/313 [00:10<00:00, 29.50it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  98%|█████████▊| 307/313 [00:10<00:00, 29.53it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  98%|█████████▊| 308/313 [00:10<00:00, 29.57it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  99%|█████████▊| 309/313 [00:10<00:00, 29.60it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  99%|█████████▉| 310/313 [00:10<00:00, 29.63it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10:  99%|█████████▉| 311/313 [00:10<00:00, 29.67it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10: 100%|█████████▉| 312/313 [00:10<00:00, 29.70it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 10: 100%|██████████| 313/313 [00:10<00:00, 29.75it/s, loss=1.3, v_num=1.21e+7]\n",
      "Epoch 11:  62%|██████▏   | 194/313 [00:07<00:04, 26.89it/s, loss=2.18, v_num=1.21e+7]"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(num_sanity_val_steps=2, gpus=1)\n",
    "trainer.fit(gat_model, qm9_train_loader, qm9_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81114f32-d951-42e7-aae9-f83a8c7756ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9658ae8-56bc-4fa1-9dbb-9cd5d2122a83",
   "metadata": {},
   "source": [
    "## checkpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "048f78f8-d7ee-4e98-b0d2-020da3a6f36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = './lightning_logs/version_12100283/checkpoints/epoch=75-step=19000.ckpt'\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "\n",
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc18ca-9e2c-4a39-9313-13964d73b080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc105e99-5098-4fc1-8861-d0250de45843",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccad97e3-dafd-4b10-afae-aaf222a21df5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import NNConv, GATConv, GCNConv, GATv2Conv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "45420da8-d22b-44c2-807b-5942e0b3adaf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExampleNet(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features):\n",
    "        super().__init__()\n",
    "        conv1_net = nn.Sequential(\n",
    "            nn.Linear(num_edge_features, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_node_features*32))\n",
    "        conv2_net = nn.Sequential(\n",
    "            nn.Linear(num_edge_features, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32*16))\n",
    "        self.conv1 = NNConv(num_node_features, 32, conv1_net)\n",
    "        self.conv2 = NNConv(32,16, conv2_net)\n",
    "        self.fc_1 = nn.Linear(16, 32)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "    def forward(self, data):\n",
    "        batch, x, edge_index, edge_attr = (\n",
    "            data.batch, data.x, data.edge_index, data.edge_attr)\n",
    "        # First graph conv layer\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        # Second graph conv layer\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = global_add_pool(x,batch)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "548d7e0f-97c2-49eb-9359-d0858494d749",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExampleNet(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features, heads=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        #self.fc1 = nn.Linear(num_node_features, 11)\n",
    "        self.conv1 = GATv2Conv(num_node_features, 32, heads=heads)\n",
    "        self.conv2 = GATv2Conv(32*heads, 20, heads=heads)\n",
    "        self.conv3 = GATv2Conv(20*heads, 10, heads=heads)\n",
    "        self.conv4 = GATv2Conv(10*heads, 5, heads=heads)\n",
    "        #self.conv5 = GATConv(20*heads, 1, heads=heads)\n",
    "        self.fc2 = nn.Linear(5*heads, 30)\n",
    "        #self.fc_2 = nn.Linear(56, 10)\n",
    "        self.out = nn.Linear(30, 1)\n",
    "    def forward(self, data):\n",
    "        batch, x, edge_index, edge_attr = (\n",
    "            data.batch, data.x, data.edge_index, data.edge_attr)\n",
    "        \n",
    "        #x = F.relu(self.fc1(x))\n",
    "        # First graph conv layer\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        # Second graph conv layer\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        \n",
    "        x = global_add_pool(x,batch)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = F.relu(self.fc_2(x))\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "dd5bd221-7617-494a-8b8e-8dbeb33f6d78",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "qm9_node_feats, qm9_edge_feats = 11, 4\n",
    "\n",
    "net = ExampleNet(qm9_node_feats, qm9_edge_feats).to(device)\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "aef7114f-9bed-46bf-be5f-dd12128e5e19",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), 1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',\n",
    "    patience=50,\n",
    "    factor=0.85,\n",
    "    min_lr=1e-7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bebd83-f838-4850-839f-752467956d2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a42b7-cbd2-4179-8dd8-2bb1bf290b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d1d62-0a3c-40ae-97b1-d6f78793e6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG",
   "language": "python",
   "name": "pyg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
